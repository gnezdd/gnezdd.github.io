[{"title":"HTTP各版本区别","url":"/2023/06/09/HTTP%E5%90%84%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB/","content":"HTTP1.0与HTTP1.1的区别长连接\n\nHTTP1.0默认适用短链接，客户端和服务器每进行一次HTTP交互就需要建立一次连接，任务结束就中断连接\n\nHTTP1.1默认使用长连接，只要任意一端没有明确提出断开连接，就一直保持TCP连接状态\n\n\n管道网络传输\n\nHTTP1.0需要收到第一个请求的回应后才可以发送第二个请求\n\nHTTP1.1使用长连接，使管道网络传输成为可能。在同一个TCP连接中，客户端可以发起多个请求，只要第一个请求发送出去了就可以发送第二个，不需要等待第一个请求的返回，可以减少整体的响应时间\n\n\nHost域\n\nHTTP1.0认为每台服务器都绑定一个唯一的IP地址，因此请求消息中的URL没有传递主机名，但是随着虚拟主机技术的发展，一台物理服务器上可以存在多个虚拟主机，共享一个IP地址，也就是说一个IP地址是可以对应多个域名的\n\n比如一台IP为A的服务器上部署着谷歌、百度、淘宝的网站，在发送请求时域名解析会解析到同一个IP地址，那么如何区分用户是要具体访问主机中的哪一个应用\n\n使用ip+port区分\n\n需要为每个网站部署一个端口，客户端在访问的时候需要直到是哪一个端口\n\n\n虚拟主机\n\n将一台完整的服务器分成若个主机，可以在单一主机上运行多个服务，客户端就可以使用同一个ip和同一个端口号访问不同的网站，通过host域进行区分\n\n通过用户请求的host域名进行区分，服务器后台解析出host域并和服务器上设置的server_name比对，如果匹配则访问，不匹配则连接丢弃报错\n\n\n\n\n\nHTTP1.1增加Host域且请求消息中如果没有Host域会报告错误400Bad Request\n\n\n断点续传\n\nHTTP1.0每次只会传输整个数据实体，没办法部分传输\n\nHTTP1.1默认支持断点续传，原理是在请求报文头中加入Range字段段\n\n\n消息通知管理\n\nHTTP1.1新增了24个错误状态响应码，如409(Conflict)表示请求的资源与资源当前状态冲突；410(Gone)表示服务器上某个资源被永久性删除\n\n缓存处理\n\nHTTP1.0使用header中的if-modified-since和expires作为缓存判断标准\n\nHTTP1.1引入了更多缓存控制策略如Entity tag，If-Unmodified-Since，If-match，If-None-Match等\n\n\nHTTP1.1和HTTP2.0的区别头部压缩\n\nHTTP1.1中Header问题\n\n固定的字段占字节大\n\n大量的请求和响应报文中许多字段重复\n\n只对body进行压缩，没有对header进行压缩\n\n\n\nHTTP2.0使用HPACK算法对header的数据进行压缩\n\nHPACK算法：在客户端和服务器两端建立字典，将字段存入字典中并生成索引号，使用索引号代表字段了\n\n静态字典\n\n为高频出现在头部的字符串和字段建立静态表，写入HTTP&#x2F;2框架中\n\n\n动态字典\n\n不在静态表范围内的头部字符串要自行构建动态表，Index从62起步，在编码解码的时候随时更新，下一次发送的时候就只需要发送一个字节的index\n\n必须同一个连接上重复传输完全相同的HTTP头部\n\n占用内存越来越大\n\n\n\n\n\n哈夫曼编码压缩整数和字符串\n\n\n\n\n二进制格式\n\n二进制：体积小、速度块、没有歧义\n\n对人不友好，但是对计算机友好，可以直接解析二进制报文，增加了数据传输效率\n\n\nHTTP1.1的报文使用文本格式，HTTP2.0使用二进制格式\n\n将报文分为头信息帧和数据帧\n\n头信息帧的最后4个字节是流标识符，最高位被保留不用，流标识位用于表示该Fream属于哪个Stream，接收方可以根据该信息从乱序的帧中找到相同Stream ID的帧从而有序组装信息\n\n\n多路复用\n\nHTTP2.0将每一个请求看成是一个流，为每个请求分配一个唯一的流id，并将请求分成多个块，不同的Stream的块是可以混杂在一起发送的，因此可以并发不同的请求\n\n流的特点\n\n流是可并发的，一个HTTP2连接上可以同时发出多个流传输数据\n\n每一个流有唯一的流ID，客户端发出为奇数，服务器为偶数\n\nStreamID不可复用，只能顺序递增，使用完后需要发出控制帧GOAWAY关闭TCP连接\n\n第0号流不能关闭，不能发送数据帧，只能发送控制帧，用于流量控制\n\n\n\n\n服务端推送\n\nHTTP1.1每一个网络资源都必须由客户端明确地请求\n\nHTTP2服务器可以主动向客户端发送消息\n\n例如浏览器请求HTML时提前将可能用到的js等静态资源主动发送给客户端减少延时等待与避免请求\n\n\n优先级\n\n客户端可以指定数据流的优先级\n\nHTTP3.0与HTTP2.0的区别HTTP2是基于TCP协议的\n\n存在队头阻塞\n\nTCP和TLS握手时延，至少需要3RTT\n\n网络迁移需要重新连接\n\n\nHTTP3将下层的TCP协议更改为UDP协议并增加了QUIC协议\n\nQUIC是一个在UDP上的伪TCP+TLS+HTTP2的多路复用协议\n\n解决HTTP2队头阻塞问题\n\nUDP不关心包的顺序，但是QUIC会\n\nQUIC保证包的可靠性，每个数据包都有一个序号唯一标识，当某个流的数据包丢失了，即使这个流的其他数据包到了也没办法被HTTP3读取，只有QUIC重传丢失的报文才会交给HTTP3\n\n其他流的数据包只要被完整接受就可以被HTTP3读取\n\nQUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响\n\n\n\n更快的连接建立\n\nHTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、OpenSSL 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手\n\nHTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果\n\nHTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的\n\n\n\n连接迁移\n\n基于TCP传输协议的HTTP协议是通过四元组确定一条TCP连接，当设备从一个网络切换到另一个网络的时候IP地址改变了，就需要断开连接重新建立连接\n\nQUIC没有使用四元组绑定连接，而是通过连接ID标识通信的两个端点，客户端和服务器各选择一组ID标识自己，因此即使移动设备网络变化导致IP地址变化了，只要仍然有上下文信息（连接ID、TLS密钥等）就可以无缝复用原连接了，消除重连成本\n\n\n\n\nHTTP3协议\n\nHTTP&#x2F;3 同 HTTP&#x2F;2 一样采用二进制帧的结构，不同的地方在于 HTTP&#x2F;2 的二进制帧里需要定义 Stream，而 HTTP&#x2F;3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP&#x2F;3 的帧的结构也变简单了\n\nHTTP&#x2F;3 在头部压缩算法这一方面也做了升级，升级成了 QPACK。与 HTTP&#x2F;2 中的 HPACK 编码方式相似，HTTP&#x2F;3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。\n\n对于静态表的变化，HTTP&#x2F;2 中的 HPACK 的静态表只有 61 项，而 HTTP&#x2F;3 中的 QPACK 的静态表扩大到 91 项。\n\nHTTP&#x2F;2 和 HTTP&#x2F;3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。\n\n所谓的动态表，在首次请求-响应后，双方会将未包含在静态表中的 Header 项更新各自的动态表，接着后续传输时仅用 1 个数字表示，然后对方可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，大大提升了编码效率。\n\n可以看到，动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来\n\nQUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：\n\n一个叫 QPACK Encoder Stream，用于将一个字典（Key-Value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；\n\n一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。\n\n这两个特殊的单向流是用来同步双方的动态表，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部\n\n也就是说要更新动态表前先通知对方，只有在得到对方的响应后才可以使用动态表中的内容\n\n\n\n\n","categories":["计算机网络"],"tags":["HTTP版本"]},{"title":"IO多路复用","url":"/2023/05/21/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"IO多路复用IO多路复用是一种同步IO模型，实现一个线程可以同时监视多个文件描述符；一旦某个文件描述符就绪，就能够通知应用程序进行相应的读写操作\n多路是指多个网络连接，复用指的是同一个线程\nLinux提供了select、poll、epoll三种接口函数实现IO多路复用\nselect&amp;poll是将文件描述符存放到文件描述符集合中，调用select&#x2F;poll将文件描述符集合拷贝到内核中，内核会遍历文件描述符集合看是否有事件发生，如果有就将对应的文件描述符标记为可读或可写，然后再将整个文件描述符集合拷贝到用户态中，在用户态进行遍历对发生了事件的文件描述符进行处理\nepoll是使用一个文件描述符管理多个文件描述符，将用户感兴趣的文件描述符添加到内核中，由内核监听并返回发生了事件的文件描述符\n为什么需要IO多路复用在没有IO多路复用之前有BIO和NIO两种实现方式，但是都有一些问题\nBIO同步阻塞\n服务端采用单线程，当accept一个请求后调用recv或send被阻塞时，没办法处理其他的请求，必须等待上一个recv或send调用完才可以处理（没办法实现并发，在同一时刻只能处理一个请求或者被阻塞）\n如果服务端采用多线程或多进程，在accept一个请求后创建一个相应的线程或进程负责这一个请求，可以实现并发，但是随着请求数量的增加会增大系统的开销（线程进程切换、进程资源的消耗、线程安全等）\n\nNIO同步非阻塞\n服务端accept一个请求后加入fds集合，每次轮询一次fds集合recv或send数据，没有数据就立即返回，不会阻塞，但是每次都需要去轮询fds，会消耗性能\n\nIO多路复用服务端采用单线程通过IO多路复用将需要监听的文件描述符集合交给内核监听，由内核返回发生了事件的文件描述符，能够在同一时刻监听多个文件描述符\n主要是IO多路复用能够在一个线程中实现并发操作（同时监听多个文件描述符）\nAPI说明select#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);\n\n返回：若有就绪描述符则为其个数，超时为0，出错-1并设置errno\n参数：除了nfds，其他都通过指针传递，以便于内核可以修改通知应用程序\n\nnfds：指定被监听的文件描述符个数，通常为监听的所有文件描述符中的最大值加1\nreadfds\\writefds\\exceptfds分别对应可读、可写和异常事件文件描述符集合，当调用select时就通过这三个参数传入进程感兴趣的文件描述符，交给内核监听。内核通过修改它们通知应用程序有哪些文件描述符就绪\ntimeout：内核会修改这个参数表示自己等待了多长的时间，但是这个参数时不能够完全信任的，因为调用失败后timeout的值是不确定的\n0：立刻返回\nNULL：一直阻塞直到有文件描述符就绪\n其他：指定阻塞等待多长时间\n\n\n\n#include &lt;sys/select.h&gt;FD_ZERO(fd_set *fdset);\t\t/* 清除fdset所有标志位 */FD_SET(int fd, fd_set fdset);\t\t/* 设置fdset标志位fd */FD_CLR(int fd, fd_set fdset);\t\t/* 清除fdset标志位fd */int FD_ISSET(int fd, fd_set *fdset);\t/* 测试fdset的位fd是否被设置 */\n\nfd_set结构体包含一个整型数组，数组中每一个元素的每一位代表一个文件描述符，相当于一个位图，fd_set能够容纳的文件描述符数量由FD_SETSIZE指定（限制了select能够监听的文件描述符数量）\npoll#include &lt;poll.h&gt;int poll(struct pollfd *fds, nfds_t nfds, int timeout);\n\n返回：若有就绪描述符则为其数目，超时为0，出错-1\n参数：\n\nnfds：被监听的文件描述符集合fds的大小\ntimeout：\n-1：一直阻塞直到某个时间发生\n0：马上返回\n其他：指定poll的超时值\n\n\n\nstruct pollfd&#123;\tint fd;\t\t\t/* 文件描述符 */\tshort events;\t\t/* 注册的事件 */\tshort revents;\t\t/* 实际发生的事件，有内核填充 */&#125;;\n\npoll支持的事件类型：\n\nepoll#include &lt;sys/epoll.h&gt;int epoll_create(int size);\n\n返回：成功返回创建的内核事件表对应的描述符，出错-1\nsize参数现在并不起作用，只是给内核一个提示，告诉它内核表需要多大，该函数返回的文件描述符将用作其他所有epoll函数的第一个参数，以指定要访问的内核事件表\n#include &lt;sys/epoll.h&gt;int epoll_ctl(int opfd, int op, int fd, struct epoll_event *event);\n\n返回：成功返回0，出错-1\nfd参数是要操作的文件描述符，op指定操作类型，操作类型有3种\n\nEPOLL_CTL_ADD：往事件表中注册fd上的事件\nEPOLL_CTL_MOD：修改fd上的注册事件\nEPOLL_CTL_DEL：删除fd上的注册事件\n\nevent指定事件类型，它是epoll_event结构指针类型。epoll支持的事件类型和poll基本相同，表示epoll事件类型的宏是在poll对应的宏加上”E”，比如epoll的数据可读事件是EPOLLIN，但epoll有两个额外的事件类型-EPOLLET和EPOLLONESHOT\nstruct epoll_event&#123;\t__uint32_t events;\t/* epoll事件 */\tepoll_data_t data;\t/* 用户数据 */&#125;;\n\ndata用于存储用户数据\ntypedef union epoll_data&#123;\tvoid *ptr;\tint fd;\tuint32_t u32;\tuint64_t u64;&#125;epoll_data_t;\n\nepoll_data_t是一个联合体，其4个成员最多使用的是fd，它指定事件所从属的目标文件描述符，ptr成员可用来指定fd相关的用户数据，但由于opoll_data_t是一个联合体，我们不能同时使用fd和ptr，如果要将文件描述符和用户数据关联起来，以实现快速的数据访问，则只能使用其他手段，比如放弃使用fd成员，而在ptr指针指向的用户数据中包含fd\n#include &lt;sys/epoll.h&gt;int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);\n\n返回：成功返回就绪的文件描述符个数，出错-1\ntimeout参数的含义与poll接口的timeout参数相同，maxevents参数指定最多监听多少个事件，它必须大于0\nepoll_wait如果检测到事件，就将所有就绪的事件从内核事件表(由epfd指定)中复制到events指定的数组中\n总结最好都搭配非阻塞IO：\n\n多路复用返回的事件不一定是可读写的，可能有发现数据已经达到通知应用程序，但是由于发现错误的校验和被丢弃，此时就没有数据可读\n\n防止程序发生阻塞\n\n\nselect&amp;poll区别：\n\nselect使用固定长度的位图表示文件描述符集合，所支持的文件描述符受到内核FD_SETSIZE限制，默认是1024；poll没有文件描述符数量的限制，是采用动态数组存储\nselect函数在会修改文件描述符集合的内容，没办法复用需要重新设置；poll是通过revents对文件描述符集合进行修改，不需要重新设置\nselect用户关心不同的事件需要添加到不同的文件描述符集合中；poll不需要，是在结构体中直接设置\nselect支持跨平台；poll不支持\n\n缺点：\n\n需要进行两次遍历与两次拷贝\n无法动态添加文件描述符，需要等前一个select&#x2F;poll返回后添加\n客户端多个连接但是少数活跃的话会导致效率比较低\n\nepoll优点：\n\n减少数据拷贝：在内核中使用红黑树对文件描述符进行管理，不需要每次都将整个文件描述符拷贝到内核中，只需要通过epoll_ctl将要变更的文件描述符交给内核\n提高检测效率：基于事件机制，有事件发生时通过回调函数添加到就绪链表中，再将就绪链表返回给用户，不需要轮询整个集合\n\n缺点：\n在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调去将发生事件的文件描述符添加到就绪链表中（红黑树中的查询）\n两种触发模式\nLT水平触发（默认）\n\n当检测到有事件发生会将事件通知应用程序，应用程序如果不处理该事件则下次再次调用时，会再次通知应用程序\n\nET边缘触发\n\n当检测到有事件发生会将此事件通知应用程序，应用程序必须立即处理该事件，如果不处理，下次调用时，不会再次通知应用程序该事件的发生\n一般和非阻塞IO配合使用：\n\nIO事件只会通知一次，应用程序不知道能够读写多少数据，所以在收到通知后应该尽可能读写数据以免错失读写机会\n\n循环执行非阻塞IO操作知道返回错误没有数据可读写\n\n\n\n选择\n\n\n大流量下使用ET性能会更好，不会频繁调用epoll_wait\nLT不会丢失数据而且可以通过使用大缓冲机制一次read就读取数据，ET需要一直读取知道返回EAGAIN（至少需要两次read）\n当没有数据可读的时候非阻塞IO就会返回EAGAGIN告诉应用程序没有数据可以读了，需要稍后再试\n\n\nLT可以照顾多个连接的公平性，不会因为某个连接数据过大影响其他连接处理消息\n\nAPI使用select#include &quot;selectServer.h&quot;#include &lt;iostream&gt;#include &lt;sys/select.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;vector&gt;using namespace std;int getMaxNumOfVector(vector&lt;int&gt; &amp;fds) &#123;    int res = 0;    for (int i = 0; i &lt; fds.size(); i++) &#123;        res = max(res,fds[i]);    &#125;    return res;&#125;vector&lt;int&gt; flipVector(vector&lt;int&gt; &amp;fds) &#123;    vector&lt;int&gt; newFds;    for (int i = 0; i &lt; fds.size(); i++) &#123;        if (fds[i] != -1) &#123;            newFds.push_back(fds[i]);        &#125;    &#125;    return newFds;&#125;int main() &#123;    int listenFd, connFd;    struct sockaddr_in server;\t// 绑定服务器并监听    listenFd = socket(AF_INET,SOCK_STREAM,0);    memset(&amp;server,0,sizeof(server));    server.sin_family = AF_INET;    server.sin_port = htons(8888);    server.sin_addr.s_addr = INADDR_ANY;    bind(listenFd,(struct sockaddr*)&amp;server,sizeof(server));    listen(listenFd,5);    // 初始化参数    fd_set readFd;    fd_set writeFd;    fd_set exceptFd;    char buff[1024];    FD_ZERO(&amp;readFd);    FD_ZERO(&amp;writeFd);    FD_ZERO(&amp;exceptFd);    vector&lt;int&gt; fds;    fds.push_back(STDIN_FILENO);    fds.push_back(listenFd);    bool running = true;    while (running) &#123;        memset(buff,0,sizeof(buff));        // 每次调用select都需要重新初始化readFd和exceptFd中的文件描述符集合        for (int i = 0; i &lt; fds.size(); i++) &#123;            FD_SET(fds[i],&amp;readFd);            if ((fds[i] != STDIN_FILENO) &amp;&amp; (fds[i] != listenFd)) &#123;                FD_SET(fds[i],&amp;exceptFd);            &#125;        &#125;\t        int eventNum = select(getMaxNumOfVector(fds) + 1, &amp;readFd, &amp;writeFd, &amp;exceptFd, NULL);        if (eventNum &lt; 0) &#123;            cerr &lt;&lt; &quot;select error&quot; &lt;&lt; endl;            break;        &#125;        for (int i = 0; i &lt; fds.size(); i++) &#123;            if (fds[i] == STDIN_FILENO) &#123;                if (FD_ISSET(STDIN_FILENO, &amp;readFd)) &#123;                    cin &gt;&gt; buff;                    if (strcmp(buff,&quot;quit&quot;) == 0) &#123;                        running = false;                        break;                    &#125; else &#123;                        cout &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125;            &#125; else if (fds[i] == listenFd) &#123;                if (FD_ISSET(listenFd, &amp;readFd)) &#123;                    connFd = accept(listenFd,NULL,NULL);                    if (connFd &lt; 0) &#123;                        running = false;                        break;                    &#125;                    fds.push_back(connFd);                    cout &lt;&lt; &quot;向fds添加&quot; &lt;&lt; connFd &lt;&lt; &quot;,fds.size:&quot; &lt;&lt; fds.size() &lt;&lt; endl;                &#125;            &#125; else &#123;                if (FD_ISSET(fds[i],&amp;readFd)) &#123;                    int len = recv(fds[i],buff,sizeof(buff)-1,0);                    if (len &lt; 0) &#123;                        cerr &lt;&lt; &quot;recv error&quot; &lt;&lt; endl;                    &#125; else if (len == 0) &#123;                        cout &lt;&lt; &quot;从fds删除&quot; &lt;&lt; fds[i] &lt;&lt; endl;                        close(fds[i]);                        // 断开连接                        fds[i] = -1;                    &#125; else &#123;                        buff[len] = &#x27;\\0&#x27;;                        cout &lt;&lt; fds[i] &lt;&lt; &quot;recv:&quot; &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125; else if (FD_ISSET(fds[i], &amp;writeFd)) &#123;                &#125; else if (FD_ISSET(fds[i],&amp;exceptFd)) &#123;                &#125;            &#125;        &#125;        fds = flipVector(fds);    &#125;    // 关闭文件描述符    for (int i = 0; i &lt; fds.size(); i++) &#123;        close(fds[i]);    &#125;    return 0;&#125;\n\n\n\npoll#include &quot;pollServer.h&quot;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/poll.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;using namespace std;struct pollfd *getPollFd(vector&lt;pollfd&gt; &amp;fds, int *ppoll_size)&#123;    struct pollfd *poll = (struct pollfd *) malloc(fds.size() * sizeof(struct pollfd));    for (int i = 0; i &lt; fds.size(); i++) &#123;        poll[i].fd = fds[i].fd;        poll[i].events = fds[i].events;    &#125;    *ppoll_size = fds.size();    return poll;&#125;vector&lt;pollfd&gt; flipVector(vector&lt;pollfd&gt; &amp;fds) &#123;    vector&lt;pollfd&gt; fdsnew;    for (int i = 0; i &lt; fds.size(); i++) &#123;        if (fds[i].fd != -1) &#123;            fdsnew.push_back(fds[i]);        &#125;    &#125;    return fdsnew;&#125;int main() &#123;    // 绑定服务器    int listenFd, connFd;    struct sockaddr_in server;    listenFd = socket(AF_INET,SOCK_STREAM,0);    memset(&amp;server,0, sizeof(server));    server.sin_addr.s_addr = INADDR_ANY;    server.sin_port = htons(8888);    server.sin_family = AF_INET;    bind(listenFd,(struct sockaddr*)&amp;server, sizeof(server));    listen(listenFd,5);    struct pollfd poll_fd;    vector&lt;struct pollfd&gt; fds;    poll_fd.fd = STDIN_FILENO;    poll_fd.events = POLLIN;    fds.push_back(poll_fd);    char buff[1024];    struct pollfd *ppoll = nullptr;    int poll_size = 0;    ppoll = getPollFd(fds,&amp;poll_size);    bool running = true;    while (running) &#123;        int oldSize = fds.size();        memset(buff,0, sizeof(buff));        int eventNum = poll(ppoll,poll_size,-1);        if (eventNum &lt; 0) &#123;            cerr &lt;&lt; &quot;poll error&quot; &lt;&lt; endl;            break;        &#125;        int fds_size = fds.size();        for (int i = 0; i &lt; fds_size; i++) &#123;            if (ppoll[i].fd == STDIN_FILENO) &#123;                if (ppoll[i].revents &amp; POLLIN) &#123;                    cin &gt;&gt; buff;                    if (strcmp(buff,&quot;quit&quot;) == 0) &#123;                        running = false;                        break;                    &#125; else &#123;                        cout &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125;            &#125; else if (ppoll[i].fd == listenFd) &#123;                if (ppoll[i].revents &amp; POLLIN) &#123;                    connFd = accept(listenFd,NULL,NULL);                    if (connFd &lt; 0) &#123;                        running = false;                        break;                    &#125;                    poll_fd.fd = connFd;                    poll_fd.events = POLLIN;                    fds.push_back(poll_fd);                    cout &lt;&lt; &quot;向fds添加&quot; &lt;&lt; connFd &lt;&lt; endl;                &#125;            &#125; else &#123;                if (ppoll[i].revents &amp; POLLIN) &#123;                    int len = recv(ppoll[i].fd,buff, sizeof(buff)-1,0);                    if (len &lt; 0) &#123;                        cerr &lt;&lt; &quot;recv error&quot; &lt;&lt; endl;                        break;                    &#125; else if (len == 0) &#123;                        cout &lt;&lt; &quot;从fds删除&quot; &lt;&lt; fds[i].fd &lt;&lt; endl;                        close(fds[i].fd);                        fds[i].events = 0;                        fds[i].fd = -1;                    &#125; else &#123;                        buff[len] = &#x27;\\0&#x27;;                        cout &lt;&lt; fds[i].fd &lt;&lt; &quot;recv:&quot; &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125;            &#125;        &#125;        fds = flipVector(fds);        if (oldSize != fds.size()) &#123;            free(ppoll);            ppoll = getPollFd(fds,&amp;poll_size);        &#125;    &#125;    for (int i = 0; i &lt; fds.size(); i++) &#123;        if (fds[i].fd != -1) &#123;            close(fds[i].fd);        &#125;    &#125;    return 0;&#125;\n\n\n\nepoll#include &quot;epollServer.h&quot;#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;using namespace std;void addfd(int epollfd, int fd)&#123;    epoll_event event;    event.data.fd = fd;    event.events = EPOLLIN;    epoll_ctl(epollfd, EPOLL_CTL_ADD, fd, &amp;event);&#125;void delfd(int epollfd, int fd)&#123;    epoll_event event;    event.data.fd = fd;    event.events = EPOLLIN;    epoll_ctl(epollfd, EPOLL_CTL_DEL, fd, &amp;event);&#125;int main(int argc, char **argv)&#123;    int listenfd, connfd;    struct sockaddr_in servaddr;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    memset(&amp;servaddr, 0, sizeof(servaddr));    servaddr.sin_family = AF_INET;    servaddr.sin_port = htons(8080);    servaddr.sin_addr.s_addr = INADDR_ANY;    bind(listenfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr));    listen(listenfd, 5);    int epollfd = epoll_create(32);    if (epollfd &lt; 0) &#123;        cerr &lt;&lt; &quot;epoll_create error&quot; &lt;&lt; endl;        exit(-1);    &#125;    addfd(epollfd, STDIN_FILENO);    addfd(epollfd, listenfd);    epoll_event events[32];    char buff[1024];    bool running = true;    while (running) &#123;        buff[0] = &#x27;\\0&#x27;;        int event_num = epoll_wait(epollfd, events, 32, -1);        if (event_num &lt; 0) &#123;            cerr &lt;&lt; &quot;epoll_wait error&quot; &lt;&lt; endl;            break;        &#125;        for (int i = 0; i &lt; event_num; i++) &#123;            int fd = events[i].data.fd;            int event = events[i].events;            if (fd == STDIN_FILENO) &#123;                // 从STDIN_FILENO中读取数据                if (event &amp; EPOLLIN) &#123;                    cin &gt;&gt; buff;                    if (strcmp(buff, &quot;quit&quot;) == 0) &#123;                        running = false;                        break;                    &#125;                    else &#123;                        cout &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125;            &#125;            else if (fd == listenfd) &#123;                if (event &amp; EPOLLIN) &#123;                    connfd = accept(listenfd, NULL, NULL);                    if (connfd &lt; 0) &#123;                        running = false;                        break;                    &#125;                    addfd(epollfd, connfd);                    cout &lt;&lt; &quot;往epoll添加 &quot; &lt;&lt; connfd &lt;&lt; endl;                &#125;            &#125;            else &#123;                if (event &amp; EPOLLIN) &#123;                    int len = recv(fd, buff, sizeof(buff) - 1, 0);                    if (len &lt; 0) &#123;                        cerr &lt;&lt; &quot;recv error&quot; &lt;&lt; endl;                    &#125;                    else if (len == 0) &#123;                        cout &lt;&lt; &quot;从epoll删除 &quot; &lt;&lt; fd &lt;&lt; endl;                        // 客户端断开了连接                        delfd(epollfd, fd);                    &#125;                    else &#123;                        buff[len] = &#x27;\\0&#x27;;                        cout &lt;&lt; fd &lt;&lt; &quot; recv: &quot; &lt;&lt; buff &lt;&lt; endl;                    &#125;                &#125;            &#125;        &#125;    &#125;    // 关闭文件描述符    close(listenfd);    return 0;&#125;\n\n","categories":["IO多路复用"],"tags":["IO多路复用"]},{"title":"Linux中进程的调度","url":"/2023/08/06/Linux%E4%B8%AD%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6/","content":"\nDeadline &gt; Realtime &gt; Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 dl_rq 里选择任务，然后从 rt_rq 里选择任务，最后从 cfs_rq 里选择任务\nLinux将按照优先级分为两种，优先级数值越小的优先级越高，实时任务优先级在099，普通任务在100139，针对不同的任务有不同的调度策略\n普通任务Deadlind和RT调度器\n\n调度策略\n\nSCHED_DEADLIND ：按照deadline继续调度，距离当前时间点最近的deadline的任务会被调度\n\nSCHED_FIFO：对于相同优先级的任务按照先来先到的原则，但是优先级更高的任务可以抢占优先级低的任务\n\nSCHED_RR：对于相同优先级发任务轮流运行，每个任务都有一定的时间片，时间片用完会被放到队尾保证相同优先级任务的公平性，但是高优先级任务可以抢占低优先级任务\n\n\n\n运行队列\n\ndl_rq、rt_rq\n\n\n\n实时任务CSF调度器\n\n调度策略\n\nSCHED_NORMAL：普通任务使用的调度策略\n\nSCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务可以适当降低优先级\n\n\n\nCFS完全公平调度算法\n\n理念：实现任务运行的公平性，保障每个任务的运行时间差不多\n\n使用虚拟运行时记录进程已经消耗了多少CPU时间，如果消耗得少那么就优先被调度；同时根据进程的权重计算虚拟运行时的增加，权重越高的进程虚拟运行时增加得越少（比如同样是增加了250ns的虚拟运行时，权重低的进程实际获取的CPU时间只有200ns，权重高的进程获得300ns）\n\n权重有优先级得来，但是会保证权重不会高于实时任务的优先级\n\n\n\n\n运行队列cfs_rq\n\n使用红黑树实现，按照虚拟运行时排序，最左侧的叶子节点就是下一次会被调度的任务\n\n\n\nLinux进程调度器发展O(n)调度器\n\n设计理念\n\n将时间分成大量时间片，每个时间片开始时调度器从就绪队列中选择优先级最高的进程执行。进程可以用尽这个时间片，如果用不完剩下的时间会增加到下一个时间片中\n\n\n时间片设计\n\n根据进程的静态优先级分配一个默认的时间片，优先级越高获得的时间片越大\n\n静态优先级\n\n进程创建时初始的优先级\n\n\n动态优先级\n\n每次进程调度的过程中会基于进程的静态优先级和进程剩下的时间片计算一个动态优先级\n\n\n\n\n数据结构\n\n使用全局队列\n\n每一层进程调度都需要遍历队列寻找最高优先级的进程\n\n\n\n\nO(1)调度器\n\n设计理念\n\n与O(n)调度器基本一致，但是获取最高优先级的进程是O(1)\n\n\n时间片设计\n\n进程的优先级数字越小优先级越高\n\n与O(n)调度器类似，但是O(1)调度器会根据平均休眠时间调整优先级（与用户交互越多的进程优先级越高）\n\n\n\n数据结构\n\n进程的优先级是0-139，O(1)调度器生成139个队列，进程根据优先级存放到对应的队列中，按照优先级执行，可以O(1)获取最高优先级的进程\n\n\n进程的运行顺序和时间片太依赖优先级，同时优先级是基于与用户交互频率，如果假设不成立那么调度器就有问题\n\n\n完全公平调度器CFS\n","categories":["操作系统"],"tags":["Linux进程的调度"]},{"title":"Linux操作命令","url":"/2023/05/13/Linux%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/","content":"用户与密码\n\n修改密码\n\npasswd\n\n\n添加用户\n\nuseradd\n\n会直接创建，需要调用passwd设置密码再进行登录\n\n创建的用户存放在&#x2F;etc&#x2F;passwd文件中，组的信息存放在&#x2F;etc&#x2F;group中\n\n\n\n\n浏览文件\n\n切换目录\n\ncd\n\n..上一级目录\n\n.当前目录\n\n\n\n列出当前目录下的文件\n\nls\n\nls -l\n\n用列表方式列出文件\n\n\n第一个字符：文件类型，-为普通文件，d为目录\n\n剩下的9个字符为模式，即权限位，3个一组，分别表示用户权限、文件所属的组权限、其他用户的权限。rwx为读、写、执行，-表示没有权限\n\n\n\n\n\n\n\n打印文件到命令行\n\ncat\n\n\ntail\n\n将指定文件的最后部分输出到标准设备中，同时当文件有更新时tail会自动刷新\n\n\n\n安装软件\n\n下载\n\nUbuntudpkg -i 文件.deb\n\ncentos下载rpmrpm -i 文件.rpm\n\n软件管家\n\nUbuntuapt-get install 软件名\n\ncentosyum install 软件名\n\n\n\n下载的配置文件：从哪里下载这些软件\n\nUbuntu&#x2F;etc&#x2F;apt&#x2F;sources.list\n\ncentos&#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo\n\n\n\n通过下载压缩包\n\n\n\n删除软件\n\nUbuntudpkg -r\n\ncentosrpm -e\n\n软件管家\n\nUbuntuapt-get purge 软件名\n\ncentosyum erase 软件名\n\n\n\n\n\n查看目前安装了哪些软件\n\nUbuntudpkg -l\n\ncentosrpm -qa\n\ndpkg -l | grep 关键词\n\n带关键词的搜索\n\n\ndpkg -l | more或dpkg -l | less\n\n使用分页展示\n\nmore只能向后翻页\n\n\n\n\n\n\n运行程序\n\n通过shell在交互命令行中运行\n\n在程序所在目录下\n\n.&#x2F;程序\n\n\n放在PATH中设置的路径下\n\n直接输入程序名\n\n\n\n\n后台运行\n\nnohup command &gt;out.file 2&gt;&amp;1 &amp;\n\n1：文件描述符1，即标准输出\n\n2：文件描述符2，标准错误输出\n\n2&gt;&amp;1：标准输出和错误输出合并到out.file中\n\n\n\nps -ef | grep 关键字 |awk ‘{print $2}’xargs kill -9\n\nps -ef列出正在运行的程序\n\nawk ‘{print $2}’：第二列的内容，即运行的程序ID\n\n通过xargs传递给kill -9\n\n\n\n\n\n以服务方式运行\n\nsystemctl start 程序\n\n开机启动\n\nsystemctl enable 程序、\n\n\n因为在&#x2F;lib&#x2F;systemd&#x2F;system目录下创建了一个.service的配置文件，定义了如何启动与关闭\n\n\n\n\nvim\n\n创建文件\n\nvim 文件名\n\n\n进入编辑模式\n\ni\n\n\n退出编辑模式\n\nesc\n\n\n保存文本\n\n:w\n\n\n退出vim\n\n:q\n\n\n直接退出不保存\n\n:q!\n\n\n\n压缩包\n\n下载压缩包\nwget 链接\n\n\n\n配置环境变量\n\nexport\n\n仅在当前命令行的会话中有效\n\n\n编辑当前用户默认工作目录中的.bashrc文件\n\n\n关机与重启\n\n关机\n\nshutdown -h now\n\n\n重启\n\nreboot\n\n\n\n","categories":["Linux命令"],"tags":["Linux操作命令"]},{"title":"Linux网络命令","url":"/2023/05/10/Linux%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/","content":"查看网络配置\n\nifconfig\n\n属于的软件包没有再维护了\n\n\nip -s addr show dev 网卡名\n\n推荐使用\n\n\n查看网口配置信息和数据包收发统计信息\n\n\n\n\n\n网络排查命令\n\nping\n\n查看对方主机是否存在\n\n\n\n没有红色部分就说明网络不可达\n\n\n\n\ntelnet\n\n模拟客户端与服务端进行交互\n\n\nnc\n\nnetcat指令，是Linux下的一个工具包需要安装，用于模拟客户端或服务端\n\n参数\n\n-u：使用UDP（默认使用TCP）\n\n-l：指定nc处于侦听状态，模拟服务端侦听并接收连接\n\n-s：指定发送数据的源IP地址（多网卡机）\n\n-v：输出交互或出错信息（调试）\n\n-w：超时秒数\n\n\n\n模拟客户端与服务端\n\n\n\n\n收发文件\n\n发送文件只能是客户端，接收文件只能是服务端\n\n接收文件nc -l ip port &gt; 文件名\n\n发送文件nc ip port &lt; 文件名\n\n\n\n\n\nnetstat\n\n用于查看网络连接状态、端口信息\n\n参数\n\n-a：显示所有选项（默认不显示LISTEN相关选项）\n\n-t：只显示与TCP相关连接\n\n-u：只显示与UDP相关连接\n\n-l：只显示处于监听状态的服务\n\n-n：不显示别名，只显示数字形式\n\n-p：显示相关连接的程序名\n\n-r：显示路由信息\n\n-e：显示扩展信息（UID等）\n\n-s：将各个协议进行统计\n\n-c：每隔一段时间执行netstat指令\n\n\n\nnetstat -anpt\n\n查看特定端口\n\nnetstat  | grep 端口号\n\n\n\n\ntcpdump\n\n网络抓包\n\n\ncurl\n\n模拟HTTP请求\n\n\n\n主机资源查看命令\n\nps\n\n查看系统中所有运行进程的详细信息\n\n参数\n\n-a：显示终端中的所有进程（除会话进程）\n\n-u：显示进程的归属用户及内存使用情况\n\n-x：显示没有与终端控制的进程\n\n-l：显示更加详细的详细\n\n-e：显示所有信息\n\n\n\n\n\n\n\ntop\n\n实时查看系统中进程运行情况(任务管理器)\n\n\n\n\n\nlsof\n\n查看进程打开的文件描述符\n\n\npidstat\n\n监控或指定进程的系统占用情况\n\nCPU、内存、磁盘IO、线程切换、线程数\n\n\n\niostat\n\n监控CPU占用率、平均负载值、IO读写速度\n\n\n\n","categories":["Linux命令"],"tags":["Linux网络命令"]},{"title":"MySQL在索引执行过程中的原则与优化机制","url":"/2023/07/05/MySQL%E5%9C%A8%E7%B4%A2%E5%BC%95%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%8E%9F%E5%88%99%E4%B8%8E%E4%BC%98%E5%8C%96%E6%9C%BA%E5%88%B6/","content":"本文主要介绍MySQL在执行查询语句使用索引时的原子以及优化措施，如MRR、索引跳跃扫描等等\n最左匹配原则对于联合索引，MySQL会一直向右匹配直到遇到范围查询（&gt;,&lt;）就停止匹配，也就是范围查询字段后面的字段无法使用到联合索引，但是对于&gt;&#x3D;、&lt;&#x3D;、between、like前缀匹配的范围查询不会停止匹配，会使用到范围查询后面的字段\n原因\n索引树是按照索引的顺序从左到右建立的，先根据第一个字段进行排序，在第一个字段相同的情况下根据第二个字段进行排序，以此类推\n除了第一个字段，其他字段都是全局无序，局部有序的\n所以在符合范围查询的字段后面的字段是无序的，无法使用到索引\n示例\n建立一个表，表中对v1、v2建立联合索引（ix_v1_v2）\nCREATE TABLE `t1` (  `id` int NOT NULL AUTO_INCREMENT,  `v1` int DEFAULT NULL,  `v2` int DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `ix_v1_v2` (`v1`,`v2`)) ;\n\n\nEXPLAIN SELECT * FROM t1 WHERE v1 &#x3D; 10 and v2 &#x3D; 10;\n\n\n等值查询能够使用到联合索引中的v1和v2\n\nEXPLAIN SELECT * FROM t1 WHERE v1 &gt; 10 and v2 &#x3D; 10;\n\n\n在符合v1 &gt; 10的联合索引中，v2的值是无序的，因此联合索引中只能使用到v1，无法使用到v2\n\nEXPLAIN SELECT * FROM t1 WHERE v1 &gt;&#x3D; 10 and v2 &#x3D; 10;\n\n\n在v1&#x3D;10的联合索引中，v2是有序的，因此在联合索引中可以使用到v2字段\n\nEXPLAIN SELECT * FROM t1 WHERE v1 BETWEEN 10 AND 20 and v2 &#x3D; 10;\n\n\nMySQL的between是闭区间也就是相当于v1 &gt;&#x3D; 10 and v1 &lt;&#x3D; 20，因此在v1&#x3D;10和v1&#x3D;20的时候，v2是有序的，因此在联合索引中可以使用到v2字段\n\nEXPLAIN SELECT * FROM t1 WHERE v1 like ‘1%’ and v2 &#x3D; 10;\n\n\n在v1&#x3D;1的时候，v2也是有序的，理由同上\n索引跳跃扫描ISSMySQL8.0之后新增的，当联合索引的某一个字段的唯一值比较少时，即使查询条件中没有使用到该字段，查询的时候也可以使用到联合索引中该字段后面的字段\n适用场景\n\n联合索引中前缀列的基数远小于后缀列的基数\n查询条件中只涉及到联合索引的后缀列\n\n失效场景\n\n查询条件中包含非索引字段\nSQL语句中带有group by或distinct\n只支持单表查询，多表关联会失效\n\n示例\nCREATE TABLE `t2` (  `id` int NOT NULL AUTO_INCREMENT,  `v1` int DEFAULT NULL,  `v2` int DEFAULT NULL,  `v3` int DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `ix_v1_v2` (`v1`,`v2`));CREATE DEFINER=`root`@`%` PROCEDURE `t2_insert_1k`()BEGIN\tDECLARE i INT;\tSET i = 0;\tWHILE i &lt; 500 DO\t\tINSERT INTO t2(v1,v2,v3) VALUES(1,i,i);\t\tSET i = i + 1;\tEND WHILE;\tWHILE i &lt; 1000 DO\t\tINSERT INTO t2(v1,v2,v3) VALUES(2,i,i);\t\tSET i = i + 1;\tEND WHILE;END\n\n\nEXPLAIN SELECT v2 FROM t2 WHERE v2 &#x3D; 10;\n\n\n适用到了索引跳跃扫描功能\n\nEXPLAIN SELECT * FROM t2 WHERE v2 &#x3D; 10;\n\n\n当查询字段中包含非索引的字段，就无法适用到索引跳跃扫描，这里为全表查询\n\nEXPLAIN SELECT DISTINCT v1 FROM t2 WHERE v2 &#x3D; 10;\n\n\n即使适用到了联合索引，但是是扫描整棵联合索引树，没有使用到索引跳跃扫描\n索引下推ICPMySQL在存储引擎层进行索引遍历过程中对索引中包含的字段先做判断，直接过滤掉不满足条件的记录再返回给server层，减少回表的次数\n示例\n对于联合索引（a, b），在执行 select * from table where a &gt; 1 and b &#x3D; 2 语句的时候，只有 a 字段能用到索引，在联合索引的索引树中找到a&gt;1的所有记录的主键值，之后对于b是否等于2的判断，是在联合索引中判断还是在主键索引中判断\n\n没有使用ICP：需要对获取到的每个主键值到聚簇索引中得到所有的数据行并交给服务层判断\n使用ICP：在获取每个主键值的同时会在联合索引树中判断是否符合要求，如果符合要求才取出对应的主键值到聚簇索引中获取数据返回给服务层\n\n索引覆盖SQL中查询的所有字段在索引B+树的叶子节点上都可以得到，不需要进行回表查询\nMRR（Multi-Range Read）通过将随机磁盘读转换为顺序磁盘读，提高查询性能\n在业务中我们应该尽量通过索引覆盖减少回表操作降低IO次数，但是很多时候二级索引树没办法满足我们的需求，还是需要进行回表才能查询到数据。这样子会增加磁盘IO的次数，并且是离散IO\n示例\nSELECT * FROM zz_student_score WHERE score BETWEEN 0 AND 59;\n在没有MRR之前的执行流程：\n\n先在成绩字段的索引上找到0分的节点，然后拿着ID去回表得到成绩零分的学生信息。\n再次回到成绩索引，继续找到所有1分的节点，继续回表得到1分的学生信息。\n再次回到成绩索引，继续找到所有2分的节点…\n周而复始，不断重复这个过程，直到将0~59分的所有学生信息全部拿到为止\n\n此时假设此时成绩0~5分的表数据，位于磁盘空间的page_01页上，而成绩为5~10分的数据，位于磁盘空间的page_02页上，成绩为10~15分的数据，又位于磁盘空间的page_01页上。此时回表查询时就会导致在page_01、page_02两页空间上来回切换，但0~5、10~15分的数据完全可以合并，然后读一次page_01就可以了，既能减少IO次数，同时还避免了离散IO\nMRR就是用来解决这个问题：\nMRR机制中，对于辅助索引中查询出的ID，会将其放到缓冲区的read_rnd_buffer中，然后等全部的索引检索工作完成后，或者缓冲区中的数据达到read_rnd_buffer_size大小时，此时MySQL会对缓冲区中的数据排序，从而得到一个有序的ID集合：rest_sort，最终再根据顺序IO去聚簇&#x2F;主键索引中回表查询数据\n索引合并index merge对多个索引分别进行扫描，然后将各种的结果进行合并\nMySQL5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。但是从5.1开始，引入了 index merge 优化技术，对同一个表可以使用多个索引分别进行条件扫描\n合并算法intersection\n将多个索引扫描得到的结果进行交集运算。一般出现在查询条件中使用AND\n条件：\n\n如果是二级索引，则必须是等值查询。如果二级索引是复合索引，则复合索引的每一列都必须覆盖到，不能只是其中的某几列\n主键索引可以是范围查询\n\nunion\n将多个索引扫描得到的结果进行并集运算。一般出现在查询条件中使用OR\n条件：\n\n如果是二级索引，则必须是等值查询。如果二级索引是复合索引，则复合索引的每一列都必须覆盖到，不能只是其中的某几列\n主键索引可以是范围查询\n\nsort_union\n在union不适用的情况下会使用\n\n二级索引也可以按照范围匹配\n复合索引也不用覆盖所有列\n\n原因\n为了 intersect 和 union 操作方便，在各个单独的索引扫描的时候，都是要获取到有序的主键值的合集，各个索引都获取到有序的主键，然后求交集或者并集就会比较方便\n因此union和intersect中：\n\n二级索引必须等值匹配，等值匹配意味着最终拿到的 B+Tree 的叶子上的主键值就是唯一的；二级索引如果可以按照范围查找，那么最终从二级索引的 B+Tree 的叶子结点上拿到的主键值就不是有序的了\n\n复合索引如果没有覆盖到所有列，意味着最终拿到的主键值也是无序\n\n\nsort_union允许二级索引按照范围匹配与不需要覆盖所有列是因为会对先拿到的主键值进行排序，之后才会去求交集或并集。相比于前两种合并方式性能会比较低\nIndex Merge已知的缺陷\n\n如果在where语句中存在多层嵌套的AND&#x2F;OR，MySQL可能不会选择最优的方案，可以尝试拆分where子句的条件进行转换\n\n(x and y) or z &#x3D;&#x3D;&gt; (x or z) and (y or z)\n(x or y) and z &#x3D;&#x3D;&gt; (x and z) or (y and z)\n\nindex merge不能用于全文索引\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"MySQL常用关键字实现原理","url":"/2023/07/10/MySQL%E5%B8%B8%E7%94%A8%E5%85%B3%E9%94%AE%E5%AD%97%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","content":"group byMySQL中group by实现方式有三种：松散索引、紧凑索引、临时文件。其中松散索引和紧凑索引是利用现有的索引来完成，临时文件是在完全无法使用索引的场景下使用的\n松散索引当MySQL完全利用索引扫描实现GROUP BY时，并不需要扫描所有满足条件的索引键即可完成操作得出结果\n举例：\ncreate index idx_gid_uid_gcon group_message(group_id,user_id,gmt_create);EXPLAIN SELECT user_id,max(gmt_create) FROM group_message WHERE group_id &lt; 10 GROUP BY group_id,user_id\\G只列重点：*************************** 1. row ***************************key: idx_gid_uid_gc Extra: Using where; Using index for group-by \n\nExtra 信息中有信息显示“Using index for group-by”，表示使用松散索引扫描实现GROUP BY 操作\n利用松散索引实现GROUP BY 条件：\n\nGROUP BY条件字段必须在同一个索引中最前面的连续位置（最左前缀原则）\n在使用GROUP BY的时候只能使用MAX或MIN这两个聚合函数（由于索引的有序性只需要扫描到一条就可以了，不需要扫描全部）\n如果引用到了该索引中GROUP BY条件之外的字段条件，必须以常量形式存储（保证查询的准确性和索引的有效性）\n当在查询中提供非常量的条件值时，数据库无法通过直接访问索引来确定匹配的行，而可能需要扫描整个数据表来找到符合条件的行\n\n\n\n比如有一个联合索引包含order_id、customer_id、order_date 和 total_amount\nSQL语句\nSELECT customer_id, SUM(total_amount) as total_sumFROM ordersWHERE order_date &gt;= DATE_SUB(NOW(), INTERVAL 1 WEEK)GROUP BY customer_idHAVING total_sum &gt; 100;\n\norder_date 字段作为 WHERE 条件的限制，由于 order_date 不是 GROUP BY 条件之一，它属于 GROUP BY 条件之外的字段条件\n此时，如果我们以非常量形式提供条件值，比如使用一个变量来表示查询的起始日期，那么数据库无法通过直接访问索引来确定匹配的行，而可能需要扫描整个数据表来找到符合条件的行。这样会导致查询效率低下\n因此，在这种情况下，我们需要将条件值限制为常量形式，如使用具体的日期值或函数表达式来表示。这样，数据库可以直接通过索引定位到满足条件的数据行，提高查询性能\n松散索引扫描的效率比较高：\n因为不需要扫描所有满足条件的行，可以提前返回\n紧凑索引在扫描索引时读取所有满足条件的索引键，然后再根据读取的数据完成GROUP BY操作得到相应的结果\nEXPLAIN SELECT max(gmt_create) FROM group_message WHERE group_id = 2 GROUP BY user_id\\G只列重点：*************************** 1. row ***************************key: idx_gid_uid_gcExtra: Using where; Using index\n\n执行计划的 Extra 信息中已经没有“Using index for group-by”了，但并不是说 MySQL 的 GROUP BY 操作并不是通过索引完成的，只不过是需要访问 WHERE 条件所限定的所有索引键信息之后才能得出结果\nMySQL Query Optimizer 首先会选择尝试通过松散索引扫描来实现 GROUP BY 操作， 当发现某些情况无法满足松散索引扫描实现 GROUP BY 的要求之后，才会尝试通过紧凑索引扫描来实现\n当 GROUP BY 条件字段并不连续或者不是索引前缀部分的时候，MySQL Query Optimizer 无法使用松散索引扫描，因为缺失的索引键信息无法得到。但是， 如果 Query 语句中存在一个常量值来引用缺失的索引键，因为常量填充了搜索关键字中的“差距”，可以形成完整的索引前缀。这些索引前缀可以用于索引查找。那么此时mysql的执行过程为先根据where语句进行一次选择，对选出来的结果集，可以利用索引。这种方式，从整体上来说，group by并没有利用索引，但是从过程来说，在选出的结果中利用了索引，这种方式就是紧凑索引\n临时表当 MySQL Query Optimizer 无法找到合适的索引可以利用的时候，就不得不先读取需要的数据，然后通过临时表和排序来完成 GROUP BY 操作\nXPLAIN SELECT max(gmt_create) FROM group_message WHERE group_id &gt; 1 and group_id &lt; 10 GROUP BY user_id\\G只列重点：*************************** 1. row ***************************key: idx_gid_uid_gcExtra: Using where; Using index; Using temporary; Using filesort\n\n采用哈希算法进行group by将相同的数值存放在一起，快速得到分组的结果，之后再进行排序，但是内存消耗会比较大\n\n哈希表需要分配内存空间存储分组结果\n哈希冲突的时候需要额外的内存空间存储冲突的值\n\n因此如果数据量太大，可以使用 SQL_BIG_RESULT 这个hint，来告诉优化器直接使用排序算法（归并排序）得到 group by 的结果\n优化思路\n尽可能让 MySQL 可以利用索引来完成 GROUP BY 操作，最好是松散索引扫描的方式\n当无法使用索引完成 GROUP BY 的时候，由于要使用到临时表且需要 filesort，所以我们必须要有足够的 sort_buffer_size 来供 MySQL 排序的时候使用，而且尽量不要进行大结果集的 GROUP BY 操作，因为如果超出系统设置的临时表大小的时候会出现将临时表数据 copy 到磁盘上面再进行操作，这时候的排序分组操作性能将是成数量级的下降\n如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null\n\nJOINJOIN类型\nINNER JOIN：将两个表中符合条件的行组合在一起。返回的结果集只包含满足连接条件的行，也就是两个表中都存在的行\nLEFT JOIN：返回左表中所有行以及符合条件的右表中的行。如果右表中没有匹配的行则用NULL填充\nRIGHT JOIN：返回右表中所有行以及符合条件的左表中的行。如果左表中没有匹配的行则用NULL填充\nFULL OUTER JOIN：返回左表和右表中所有行，如果一个表中没有匹配的行，则用NULL填充\nCROSS JOIN：返回两个表中所有可能的组合，也就是第一个表的每一行和第二个表的每一行进行组合（笛卡尔积）\n\nJOIN算法Netsted-Loop Join算法（NLJ）两张表的user_code都是索引\nmysql&gt; SELECT u.`name`, u.user_code, o.order_name FROM `user` u JOIN `order` o ON u.user_code = o.user_code;\n\n\n从order中读入一行记录\n在记录中取出user_code字段到user中查找\nuser表根据索引找到满足条件的行字段，和上面的记录组成一行\n重复1~3，直到user表遍历结束\n\n从一个表中取出一行，然后在另一个表中扫描所有行，查找与之匹配的行\n时间复杂度：O(M * N)\n为什么需要小表驱动大表：\n假设被驱动表的行数是M。 每次在被驱动表查一行数据， 需要先搜索索引a， 再搜索主键索引。每次搜索一棵树近似复杂度是logM， 所以在被驱动表上查一行的时间复杂度是 2∗logM\n假设驱动表的行数是N， 执行过程就要扫描驱动表N行， 然后对于每一行， 到被驱动表上匹配一次。因此整个执行过程， 近似复杂度是N * 2 * logM\nN对扫描行数的影响更大， 因此应该让小表来做驱动表\nBlock Netsted-Loop Join算法（BNL）两张表的user_code都没有索引\nEXPLAIN SELECT u.`name`, u.user_code, o.order_name FROM `user` u JOIN `order` o ON u.user_code = o.user_code\n\nexplain时Extral列会出现Using join buffer (Block Nested Loop)\n\n从user表中读入name,user_code字段数据存放到线程内存join_buffer中\n扫描order表，将order表中的每一行取出和join_buffer中的数据做对比，满足join条件的作为结果集的一部分返回\n\nJoin Buffer是线程内存，在查询结束后会是否。大小有限制，默认是256K，当不够存放数据时会分段查询（也就是在user表中取出一部分，扫描order表，然后继续从user表中取出一部分，扫描order表……）\n时间复杂度：O（M + M * N）\n没有索引时优化的NLJ算法：\n\n减少磁盘IO与在内存中操作：传统的 NLJ 算法在每次比较时需要从磁盘读取内部表的一行数据。而 BNL 算法将内部表分成多个块，并且将一个块的数据加载到内存，这样就可以减少频繁的磁盘 I&#x2F;O 操作，提高查询效率\n适应内存限制：当内存有限时，BNL 算法可以根据可用内存大小灵活调整块的大小，以适应内存限制。这使得 BNL 算法更具可扩展性，可以在不同的硬件配置下工作\n减少比较次数：BNL 算法通过将内部表分成多个块，每次只加载一个块进行比较，减少了比较的次数\n数据分块：BNL 算法将内部表划分为多个块，并逐个加载到内存中进行处理。每次只加载一个块的数据，并与外部表进行比较。这样可以避免一次性加载整个内部表并与外部表的每一行进行比较，从而减少了比较次数\n提前结束比较：在 BNL 算法中，如果已经找到了与外部表一行匹配的内部表行，就可以提前结束当前块的比较过程。因为在当前块内，已经找到了匹配的行，后续的比较不再需要执行。这样可以节省计算资源，进一步减少比较次数\n\n\n\nHash JoinMySQL8.0.20开始使用Hash Join替代BNL算法\nSELECT given_name,country_name FROM persons JOIN countries ON persons.country_id = countries.country_id;\n\nhash join分为两个阶段：\n\nbuild构建阶段：使用Join字段作为哈希表key，在内存中构建Hash表（会选择结果集比较小的去构建（以字节为单位进行比较）\nprobe探测阶段：逐行遍历被驱动表，计算join条件的hash值并在hash表中查找，如果匹配则记录下来，直到被驱动表遍历完成\n\n内存****中hash表的大小是由参数join_buffer_size控制的如果构建的hash表内存大于可用内存怎么办？\n服务器会将多余的构建写入磁盘的多个文件中，并且数值文件的数量，确保最大的文件大小和join_buffer_size一致\n每行数据写入哪个块文件是通过计算 join 属性的哈希来确定的。但是此时使用的哈希函数与内存中生成阶段使用的哈希函数不同\n在探测阶段，服务器对于另一张表每一行数据使用同样的hash算法进行分区。这样就可以确定两个输入之间的匹配行将位于同一对文件中\n探测阶段完成后，开始从磁盘读取文件。首先会将build构建阶段的第一个文件加载到内存中哈希表中（解释了为什么希望最大的文件大小与内存一致），接着读取在探测阶段生成的文件，在内存哈希表中进行匹配\n因此可以得出对两个操作使用相同的哈希函数，那么在将构建文件加载到哈希表中时，我们会得到一个非常糟糕的哈希表，因为同一个文件中的所有行都将哈希为相同的值\n时间复杂度：O（M + N）\n为什么替换BNL：\n\n笛卡尔积问题：当两个表进行连接操作时，如果没有合适的连接谓词或者数据分布不均匀，BNL 可能会生成巨大的笛卡尔积结果，导致性能低下。而 Hash Join 则可以通过哈希算法将连接条件相符的行分配到同一个哈希桶中，避免了笛卡尔积问题\n\n优化思路NLJ算法优化：小表驱动大表，在join的时候如果明确知道哪张表是小表时可以使用straight_join写法固定连接驱动方式\nBNL算法优化：\n\n给被驱动表的join字段加上索引，把BNL算法转成NLJ算法\n无法设置索引的情况可以通过设置join_buffer_size参数来控制Join Buffer的大小，以减少分段查询次数\n\nHash Join算法优化：增加 join_buffer_size值避免生成文件\nin &amp; existsinin执行流程：查询子查询的表且内外表有关联时，先执行内层表的子查询，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选，得到结果集。所以相对内表比较小的时候，in的速度较快\nin列表的处理：\n\n小列表：将列表中的值硬编码为条件，通过or运算符连接起来\n大列表：看成是范围区间，比如in（a,b），会看成是[a,a]、[b,b]，方便后续进行范围查询操作\n\n重复值会自动提出\n参数即使乱序也会重新排序\nMySQL 在执行 IN 运算符时有以下几种实现方式：\n\n线性搜索：当IN列表比较小或没有合适的所有时，MySQL会逐个比较列的值\n排序和二分查找：如果 IN 列表是有序的，并且存在合适的索引，MySQL 可以通过排序列表并使用二分查找算法来快速定位匹配的值\n哈希表查找：对于大型的 IN 列表，MySQL 可以将列表中的值构建成一个哈希表，并使用哈希函数将列的值映射到哈希表中的桶。然后，MySQL 可以通过查找哈希表来判断值是否存在，从而加快查询速度\n\n系统变量eq_range_index_dive_limit对IN子句的影响\nMySQL优化器需要去分析一下如何执行查询，需要判断键值在范围区间的记录共有多少条，然后通过一定方式计算出成本，与全表扫描的成本相对比，选取成本更低的那种方式执行查询\n对于包含IN子句条件的查询来说，需要依次分析一下每一个范围区间中的记录数量是多少。MySQL优化器针对IN子句对应的范围区间的多少而指定了不同的策略：\n\n如果IN子句对应的范围区间比较少，那么将率先去访问一下存储引擎，看一下每个范围区间中的记录有多少条（如果范围区间的记录比较少，那么统计结果就是精确的，反之会采用一定的手段计算一个模糊的值），这种在查询真正执行前优化器就率先访问索引来计算需要扫描的索引记录数量的方式称之为index dive\n如果IN子句对应的范围区间比较多，这样就不能采用index dive的方式去真正的访问二级索引idx_key1（因为那将耗费大量的时间），而是需要采用之前在背地里产生的一些统计数据去估算匹配的二级索引记录有多少条（很显然根据统计数据去估算记录条数比index dive的方式精确性差了很多）\n\n当范围区间个数小于eq_range_index_dive_limit时，将采用index dive的统计方式，否则将采用index statistic的统计方式\nexistsexists执行流程：指定一个子查询，检测行的存在。遍历循环外表，然后看外表中的记录有没有和内表的数据一样的，匹配上就将结果放入结果集中\n参考文章MySQL中GROUP BY的实现与优化\nMySQL——JOIN详解与优化\nMySQL中包含IN子句的语句是怎样执行的\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"《高性能MySQL》读书笔记performanceSchema","url":"/2023/06/28/Schema/","content":"performance_schema是MySQL中的一个数据库，使用 performance_schema 存储引擎，提供了有关MySQL服务器内部运行的操作上的底层指标，算是对MySQL 服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息\n工作机制程序插栓：在MySQL代码中插入探测代码，以获取想要了解的信息\n消费者表：存储关于程序插栓代码信息的表。比如为查询模块添加插桩，相应的消费者表将记录诸如执行总数、未使用索引的次数、花费的时间等信息\n\n当应用程序用户连接到MySQL并执行被测量的插桩指令时，performance_schema将每个检查的调用封装到两个宏中，然后将结果记录在相应的消费者表中\n使用检查当前MySQL版本是否支持\n查看是否支持performance_schema存储引擎：在INFORMATION_SCHEMA.ENGINES表或show engines语句的输出中查看对应Support字段值是否为YES\n\n\n\n是否启用performance_schema：performance_schema 在 MySQL 5.6 及之前的版本中默认没有启用，在 MySQL 5.7及之后的版本中才修改为默认启用\n\n\n相关表setup_instruments：所有支持的插栓列表\n消费者表：包含100多个表，可根据用途大致分类：\n\n当前和历史数据：\n*_current：当前服务器上进行中的事件\n*_history：每个线程最近完成的10个事件\n*_history_long：每个线程最近完成的10000个事件\nevents_waits：底层服务器等待\nevents_statements：SQL查询语句\nevents_stages：配置文件信息，比如创建临时表或发送数据\nevents_transactions：事务\n\n\n汇总表和摘要\n汇总表：保存有关该表建议的内容的聚合信息。如memory_summary_by_thread_by_event_name表保存了用户连接或任何后台线程的每个MySQL线程的聚合内存使用情况\n摘要：通过删除查询中的变量来聚合查询的方法，使Performance Schema不需要单独保留查询的每个变体\n\n\n实例表：指对象实例，用于MySQL安装程序。例如file_instances表包含文件名和访问这些文件的线程数\n设置表：用于performance_schema的运行时设置\n其他…\n\n检查SQL语句需要启用statement类型的插栓：\n\n常规SQL语句：\n存储在events_statements_current、events_statements_history和events_statements_history_long表中。通过这三张表可以获取到SQL执行的相关信息，进而分析SQL瓶颈、实例读写性能等等\n其中可以参考的需要优化查询的指标的列如下所示：\n\n\n语句剖析：\nevents_stages_[current|history|history_long]表包含剖析信息，例如MySQL在创建临时表、更新或等待锁时花费了多少时间\n检查内存使用情况需要启用memory类的插桩\nPerformance Schema将内存使用统计信息存储在摘要表中，摘要表的名称以memory_summary_前缀开头。内存使用聚合统计\n弊端\n内存消耗：Performance Schema收集的数据保存在内存中。performance_schema中的一些表支持自动伸缩，这意味着它们在启动时分配最小数量的内存，并根据需要调整其大小。然而，一旦分配了内存，即使禁用了特定的插桩并截断了表，也不会再释放该内存，除非重启实例\nCPU消耗：每个插桩指令的调用都会再添加两个宏调用，以将数据存储在performance_schema中。这意味着插桩越多，CPU的使用率就越高\n只在特定的插栓和用户启用后才收集数据：如果在禁用所有插桩的情况下启动服务器，然后决定检测内存使用情况，则无法知道全局缓冲区（如InnoDB缓冲池）分配的确切数量，因为在启用内存插桩之前已分配了该缓冲区\n\n建议应该启用Performance Schema，按需动态地启用插桩和消费者表，通过它们提供的数据可以解决可能存在的任何问题——查询性能、锁定、磁盘I&#x2F;O、错误等\n","categories":["MySQL"],"tags":["读书笔记"]},{"title":"《高性能MySQL》读书笔记创建高性能的索引","url":"/2023/07/02/%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E7%B4%A2%E5%BC%95/","content":"索引的创建使用策略前缀索引和索引的选择性优点：提高索引的性能、节省索引空间\n缺点：降低索引的选择性\n索引的选择性：不重复的索引值（也称为基数，cardinality）和数据表的记录总数(＃T)的比值\n索引的选择性越高，在查找的时候就可以过滤掉越多的行\n对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL并不支持对这些列的完整内容进行索引\n确定合适的前缀长度先获取完整列的选择性，然后不断增加前缀长度比较，直到获取到的选择性接近完整列的选择性\n方式一：select count(*) as c, left(列,长度) as pref from xxx group by pref order by c desc limit n;\n方式二：select count(distinct left(列,长度)) &#x2F; count(*);\n方式二在数据发布不均匀的情况下可能会选择出错误的前缀长度\n多列索引索引合并：MySQL提供的策略，在一定程度上可以使用表中的多个单列索引定位指定的行\n如果在explain是看到了使用索引合并，一般说明索引创建得比较糟糕，需要检查优化：\n\n当优化器需要对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引\n当优化器需要对多个索引做联合操作时（通常有多个OR条件），通常需要在算法的缓存、排序和合并操作上耗费大量CPU和内存资源，尤其是当其中有些索引的选择性不高，需要合并扫描返回的大量数据的时候\n更重要的是，优化器不会把这些操作计算到“查询成本”(cost)中，优化器只关心随机页面读取。这会使得查询的成本被“低估”，导致该执行计划还不如直接进行全表扫描。这样做不但会消耗更多的CPU和内存资源，还可能会影响并发的查询，但如果单独运行这样的查询则往往会忽略对并发性的影响\n\n避免使用到索引合并：\n\n通过参数optimizer_switch来关闭索引合并功能\n使用IGNORE INDEX语法让优化器强制忽略掉某些索引，从而避免优化器使用包含索引合并的执行计划\n\n选择合适的索引列顺序考虑因素：查询局中的排序、分组、条件\n索引的选择性和基数\n覆盖索引使用索引扫描结果做排序维护并修复损坏的表即使用正确的数据类型创建了表并加上了合适的索引，工作也没有结束：还需要维护表和索引来确保它们都能正常工作。维护表有三个主要目的：找到并修复损坏的表，维护准确的索引统计信息，减少碎片\n找到并修复损坏的表CHECK TABLE来检查是否发生了表损坏（注意，有些存储引擎不支持该命令；而有些存储引擎则支持以不同的选项来控制检查表的强度）。CHECK TABLE通常能够找出大多数的表和索引的错误\n使用REPAIR TABLE命令来修复损坏的表，但同样不是所有的存储引擎都支持该命令。如果存储引擎不支持，可通过一个不做任何操作(n o-o p)的ALTER操作来重建表\n……\n更新索引统计信息如果存储引擎向优化器提供的扫描行数信息不准确，或者执行计划本身太复杂以致无法准确地获取各个阶段匹配的行数，那么优化器会使用索引统计信息来估算扫描行数。MySQL的优化器使用的是基于成本的模型，而衡量成本的主要指标就是一个查询需要扫描多少行。如果表没有统计信息，或者统计信息不准确，优化器就很有可能做出错误的决定。可以通过运行ANALYZE TABLE来重新生成统计信息，以解决这个问题\nInnoDB会在表首次打开，或者执行ANALYZE TABLE，或者表的大小发生非常大的变化时计算索引的统计信息\n问题：如果服务器上有大量的数据表，这可能会带来严重的问题，尤其是当I&#x2F;O比较慢的时候。客户端程序或者监控工具触发索引信息采样更新时可能会导致大量的锁，并给服务器带来很多额外的压力，这会让用户因为启动时间漫长而感到沮丧\n可以关闭innodb_stats_on_metadata参数来避免上面提到的问题\n减少索引和数据的碎片数据碎片：\n\n行碎片：数据被存储在多个地方的多个片段中\n行间碎片：逻辑上顺序的页或行在磁盘上不是顺序存储的\n剩余空间碎片：数据页中有大量的空闲空间，导致服务器读取大量不需要的数据，造成浪费\n\n可以通过执行OPTIMIZE TABLE或者导出再导入的方式来重新整理数据。这对多数存储引擎都是有效的。对于那些不支持OPTIMIZE TABLE的存储引擎，可以通过一个不做任何操作(n o-o p)的ALTER TABLE操作来重建表\n","categories":["MySQL"],"tags":["读书笔记"]},{"title":"哈希算法&一致性哈希","url":"/2023/08/06/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/","content":"传统hash算法\n\n通过将key进行hash计算后对节点数量取模将数据分发到不同的节点上\n\n哈希表大小改变的话会导致所有的节点都需要重新计算存储\n\n\n一致性哈希算法（分布式系统负载均衡的首选算法）\n\n对key进行hash计算后对2^32取模，并按顺时针方式为数据寻找存储的节点\n\n流程\n\n组织hash环：将0~2^32-1数字按顺时针方向组织成一个圆环\n\n\n\n\n确定服务器在哈希环上位置：对服务器的key进行hash计算后对2^32取模，得到的数据就是在哈希环上的位置\n\n\n\n\n将数据映射到哈希环上：对数据的key进行hash计算后对2^32取模得到映射后的数据，然后按顺时针方向计算，将数据存储到离自己最近的机器中\n\n1和2被存储到A中，3被存储到B中，4被存储到C中\n\n\n\n\n优点\n\n节点的增加\n\n比如增加节点D被映射到CB节点中间，这样子就会4就会被迁移到D中，其他对象还是保持原有的存储位置\n\n\n节点的删除\n\n比如B节点被删除了，按照顺时针迁移的方法3会被存储到C节点中，只是3的映射位置发生改变，其他数据没有改动\n\n\n节点的增减只需要重定位环空间中的一小部分数据，只有部分缓存会失效\n\n\n\n缺点\n\nhash环倾斜：在节点太少情况下容易因为节点分布不均匀造成数据倾斜（缓存对象大部分集中在某一台服务器上）\n\n虚拟节点机制：对每一个节点计算多个哈希，每个计算结果都放置一个该服务节点，这样子一个实际的节点就会对应多个虚拟节点，虚拟节点越多，hash环上节点越多，缓存被均匀分布的概率就越大，hash环倾斜影响就越小\n\n\n\n\n为什么hashmap是两倍扩容\n\n首先需要直到hashmap中数据是怎么分配的\n\n要存入一个数据前会先对key进行哈希计算后得到hash值，再将hash值和（哈希表长度-1）做按位与运算\n\n采用按位与是因为计算机中按位运算的效率比较高，不用%\n\n\n\n由于哈希表长度是2倍扩容，所以哈希表长度减1后所有的二进制位都是1，在于数据hash值做按位于的时候数据能够充分扩散开减少哈希碰撞（否则如果有1个位置是0就导致这个位置得到的结果是0，也就是说将位置的影响交给数据，不交给哈希表长度）\n\n尽可能减少元素位置的移动\n\n以二次幂扩容容器中的元素要么保持原来的位置，要么以二次幂的偏移量出现在新表中\n\n\n\n","categories":["数据结构"],"tags":["哈希算法"]},{"title":"慢SQL治理实战总结","url":"/2023/07/10/%E6%85%A2SQL%E6%B2%BB%E7%90%86%E5%AE%9E%E6%88%98%E6%80%BB%E7%BB%93/","content":"在企业内部对于慢查SQL的优化主要经历以下的几个步骤：\n\n在慢SQL的优化过程中，可以从以下五个角度去进行思考优化：SQL优化、资源占用、业务改造、数据减少、源头替换。\n在治理慢查的过程中，SQL语句的使用问题是导致慢SQL的主要因素，因此本文主要从SQL优化角度出发，对慢SQL的常见原因和特征进行分析，介绍慢SQL的优化过程以及一些有效的调优技巧和工具，希望能够提供一些有用的方法和策略，帮助大家更好地应对慢SQL问题，并最终实现提升系统性能和优化用户体验的目标。\nSQL优化SQL语句的优化方式主要是通过选择合适的索引、优化查询语句、避免全表扫描等提高查询效率，减少慢SQL的出现\n索引索引主要用于加快数据的查询速度，有了正确的索引，数据库就可以根据索引的数据结构快速定位到匹配的数据行，从而提高查询效率和响应速度。在慢SQL中由于索引导致的主要有两个方面：索引缺失 与 索引失效\n索引缺失select * from t1 where text3 = &#x27;text898&#x27;\n\ntext3列没有索引的情况下：\n\ntext3列增加了索引：\n\n建议\n一般在以下场景中需要为相应的列创建索引：\n\n字段有唯一性限制\n经常用于where查询条件的字段\n经常用于group by 和 order by的字段，可以避免排序\n\n但是并不是需要为每个字段都添加上索引，有一些场景下添加上索引反而会加重DB的负担：\n\n不用于查询条件的字段\n字段中存在大量重复的数据\n数据量太少\n频繁更新的字段（考虑）\n\n注意：随着数据的增长和变化，索引的有效性可能会下降。定期评估和优化现有索引是十分必要的。可以通过删除不再使用的索引、调整索引的顺序和选择适当的索引类型等方式来进行索引维护和优化\n索引失效索引失效会导致SQL的执行变为全表扫描或选择错误的索引，在explain中一般是type&#x3D;ALL或type&#x3D;index\n索引失效原因：\n\n索引字段发送隐式转换\n数字转换为字符串会发生隐式转换失效\n字符串转换为数字是自动转换，不会导致索引失效\n通过在explain语句后增加extendedexplain extended sql语句，再执行show warnings查看是否存在隐式转换以及哪个字段存在隐式转换\n\n\n使用 非&#x2F;不等于（!&#x3D;、not in）查询时可能会导致索引失效\n在满足索引覆盖的情况下可能会走索引\n\n\n在查询条件中对索引使用函数或表达式计算\n比如from_unixtime(create_time) &#x3D; ’2019-12-01’就不能使用到索引：需要先做一次全表扫描，将字段上的所有值使用表达式作用后再进行匹配，从而会导致Mysql放弃走索引。所以语句应该写成create_time &#x3D; unix_timestamp(’2019-12-01’);\n\n\n没有遵循最左前缀匹配原则，比如联合索引中没有使用到第一列索引、使用左右模糊匹配\n在where子句中，or一些条件列是索引列，一些不是，会导致索引失效，直接全表扫描\n索引的可选择性差（数据发布严重倾斜或区分度不高）\nMYSQL查询优化器可能认为返回的数据量本身就很多，通过索引扫描并不能减少多少开销，此时选择全表扫描的权重会提高很多\n一般认为区分度 &gt; 0.1的查询字段可以建立索引（经验性指标，一般要进行实际的测试，比如使用前缀索引时，不断尝试直到选择到合适的前缀长度以及合适的区分度）\n\n\nIS NOT NULL 或 IS NULL条件查询也可能导致索引失效\n当索引字段不可以为空（null）时\nis null 不会使用索引，因为条件失效无法查询\n只有使用is not null 返回的结果集中只包含索引字段时，才使用索引，因为实现索引覆盖，优化器认为此时成本较小\n\n\n当索引字段可以为空（null）时\n使用 is null 会使用索引，因为NULL值在SQL中被认为是列中最小的值，存储在最左边，所以可以通过索引快速定位\n使用 is not null 返回的结果集中只包含索引字段时，才会使用索引，因为实现索引覆盖\n\n\n\n\n\n总结来说，要让避免索引失效的原则为：遵循最左前缀原则、避免使用函数和表达式、避免隐式转换、尽量实现****索引覆盖\n建议\n\n修改SQL语句\nforce index强制使用索引\nignore index忽略特定索引\n\nSQL语句优化分页写法（深翻页）最常见的分页写法就是使用limit，在分页查询时，会在 LIMIT 后面传两个参数，一个是偏移量(offset)，一个是获取的条数(limit)。\n实现方式是先查询offset+limit条数据，再将offset条数据丢弃给用户返回剩下的limit条数据。比如limit 10000,10实际上是mysql查找到前10010条数据，之后丢弃前面的10000行后再返回\n这样子当偏移量很小时，查询速度很快，但是随着 offset 变大时，查询速度会越来越慢，因为查找的数据越来越多\n在limit0,10的情况下执行速度很快，基本可以忽略不计\n\n但是当limit n，n是值越来越大时，就导致查询时间增加了\n\n建议\n\n方式一：\n\nselect * from t1 where id &gt;= 300000 order by id limit 10\n\n\n避免了扫描前offset条记录\n但是每次查询都需要拿到上一页的最大&#x2F;小id。比如当前在第3页，需要查询第5页的数据就没办法了\n\n方式二\n\n结合普通limit与方式一，解决方式二的问题，但是offset要尽量小\nselect * from t1 where id &gt; 300000 order by id limit 10, 10\n\n\n\n方式三：\n\nselect * from t1 as a inner join (select id from t1 order by id limit 300000, 10) as b on a.id = b.id order by a.id\n\n由于内部的子查询只扫描了id字段，而不是全表，所以性能会比较强\n\n这种情况下还是扫描聚簇索引树，可能难以理解并且优化效果不是很明显。在order by换成其他字段达到索引覆盖的情况下会比较容易理解\n\n方式四：\n\nselect * from t1 where id &gt; (select id from t1 order by id limit 300000, 1) limit 10\n\n同样是通过子查询扫描字段id，但是性能会略好于方式三，因为它不需要进行表的关联，而是一个简单的比较，在不知道上一页最大id的情况下，是比较推荐的用法\n\n最大最小写法MySQL提供了max()和min()用于获取最大最小值，但是优化得不是很好\ntext1没有索引，因此会全表扫描获取最小的id\n\n建议：\n由于id是主键我们可以知道第一次找到的记录对应的id就是我们需要的结果，所以可以根据结果的有序性修改SQL语句\nselect id from t1 where text1 = &#x27;dd&#x27; limit 1\n\n\n最大值同理\norder by排序问题MySQL进行排序是一个成本比较高的操作：\n\n全字段排序会在sort_buffer中建立临时表进行排序\n基于rowid排序不仅需要建立临时表，还会涉及回表操作\n\n在需要排序时会在explain的Extra字段中出现Using filesort\nselect * from t1 where v1 &lt; 100 order by v1\n\n\n建议：\n对于索引是本来就是有序的，所以可以给order by字段加上索引\n\n如果order by后面的字段是单个索引，需要order by 条件要与where中条件一致，否则order by不会利用索引进行排序\n如果order by 最后的字段是组合索引的一部分，需要把放在索引组合顺序的最后\n\n\ngroup by临时表问题\n内存占用：group by语句由于可能会建立内部临时表，用于保存和统计中间结果。首先会使用内存临时表，但是内存临时表的大小是有限制的，由参数 tmp_table_size 控制，当超过此限制时会把内存临时表转成磁盘临时表。因此内部临时表的存在会影响内存和磁盘的空间，且需要构造的是一个带唯一索引的表，执行代价都是比较高的。因此需要尽量避免内部临时表的建立\n额外排序：group by column默认会根据column排序，因此还会触发排序开销问题\n\n\n建议：\n\n让 group by 字段用上表的索引，确认方法是 explain 的Extra结果里有没有 Using temporary 和 Using filesort；通过索引建立，只需要顺序扫描到数据结束，就可以拿到 group by 的结果，不需要临时表，也不需要再额外排序\n\n\n\n如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null\n如果 group by 需要统计的数据量不大，尽量只使用内存临时表；可以通过适当调大tmp_table_size 参数，来避免用到磁盘临时表\n如果数据量实在太大，使用 SQL_BIG_RESULT 这个hint，来告诉优化器直接使用排序算法得到 group by 的结果\n\njoin当关联被驱动表上使用到索引时，会使用 Index Nested-Loop Join （NLJ）算法\n当关联被驱动表上没有使用到索引时（即t2的字段a无索引），会使用 Block Nested-Loop Join（BNL）算法\n建议：\nNLJ算法优化：小表驱动大表，在join的时候如果明确知道哪张表是小表时可以使用straight_join写法固定连接驱动方式\nBNL算法优化：\n\n给被驱动表的join字段加上索引，把BNL算法转成NLJ算法\n无法设置索引的情况可以通过设置join_buffer_size参数来控制Join Buffer的大小，以减少分段查询次数\n\nHash Join算法优化：增加 join_buffer_size值避免生成文件\nin &amp; existsin执行流程：查询子查询的表且内外表有关联时，先执行内层表的子查询，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选，得到结果集。所以相对内表比较小的时候，in的速度较快\nexists执行流程：指定一个子查询，检测行的存在。遍历循环外表，然后看外表中的记录有没有和内表的数据一样的，匹配上就将结果放入结果集中\n建议：\n遵循小表驱动大表：exists是以外层表为驱动表、IN是先执行内层表的****子查询。如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用in；反之如果外层的主查询记录较少，子查询中的表大且又有索引时使用exists\nnot in &amp; not existsnot in使用的是全表扫描没有用到索引；而not exists在子查询依然能用到表上的索引\n建议：\n使用not exists代替not in\n查询记录是否存在在很多时候开发人员判断某一条件对应的记录是否存在时会采用select count(*)，但是这样子会导致扫描所有符合条件的数据\n建议：\n改用limit 1，这样子数据库查询到一条符合条件的记录就会返回，不需要再继续查找还有多少条记录\n资源占用\n锁资源等待：在读写很热的表上，通常会发生锁资源争夺，从而导致慢查询的情况\n谨慎使用for update\n增删改尽量使用到索引\n降低并发，避免对同一条数据进行反复修改\n\n\n网络波动：往客户端发送数据时发生网络波动导致的慢查询\n硬件配置：CPU利用率高，磁盘IO经常满载，导致慢查询\n\n在高并发、高流量下，数据库所在机器的负载load过高也会导致SQL整体执行时间过长，这时可能需要从机器和实例的分配，分布式部署，分库分表，读写分离等角度进行优化\n业务改造\n是不是真的需要全部查出来，还是取其中的top N就能够满足需求了\n查询条件过多的情况下，能否前端页面提示限制过多的查询条件的使用\n针对实时导出的数据，涉及到实时查DB导出大量数据时，限制导出数据量 or 走T+1的离线导出是不是也是可以的\n现在业务上需要做数据搜索，使用了 LIKE “%关键词%” 做全模糊查询，从而导致了慢SQL。是不是可以让业务方妥协下，最右模糊匹配，这样就可以利用上索引了\n\n源头替换Mysql并不是任何的查询场景都是适合的，如需要支持全模糊搜索时，全模糊的like是无法走到索引的。同时结合数据本身的生命周期，对于热点数据，可以考虑存储到缓存解决。因此针对不适合mysql数据源的情况，我们需要替代新的存储介质\n\n有like的全模糊的查询，比如基于文本内容去查订单信息，需要接搜索引擎解决\n有热点数据的查询，考虑是否要接缓存解决\n针对复杂条件的海量数据查询，可以考虑切换到OLAP(Online Analytical Processing)，可以考虑接Hybrid DB或ADB通道\n有些场景Mysql不适用，需要用K-V的数据库，HBASE等列式存储的存储引擎\n\n数据减少SQL本身的性能已经到达极限了，但是耗时仍然很长，可能由于数据量或索引数据都比较大了。因此需要从数据量级减少的角度去处理\n\n使用分库分表。由于单表的数据量过大，例如达到千万级别的数据了，需要使用分库分表技术拆分后减轻单库单表的单点压力\n定时清理终态数据。针对已经状态为终态的业务单据或明显信息，可以使用idb历史数据清理的方式配置定时自动清理。如针对我们的仓储库存操作明细为完结状态的数据，我们只保留最近1天的数据在db中，其他直接删除，减少db查询压力\n统计类查询可以单独维护汇总数据表。参考数据仓库中的数据分层设计，基于明细数据，抽出一张指标汇总表，或7天&#x2F;15天等的视图数据进行预计算。此类汇总表数据量级相比明细表下降很多，从而避免直接根据大量明细查询聚合造成慢sql\n\n实践举例\nSQL语句分析\n分析sql时间点发现固定db某个示例会导致RT尖峰抖动，发现磁盘也有相应问题。怀疑DB某些库磁盘问题导致，联系DBA确认后进行主备切换解决\n核销慢sql查询迟迟难以解决。发现库存核销记录每天增量数据达到百万级别，但是核销创建状态记录只有20%~30%左右，因此对完结状态的核销记录idb配置定时清理，由15天缩短到2天，减少db数据量\n库存sn查询涉及复杂查询，采用切换到OLAP链路，通过数据同步中间件完成从db到HybridDB一键同步，切换数据源后问题解决\n\n参考文章MySQL中IS NULL、IS NOT NULL、!&#x3D;是否走索引\n慢SQL治理实践小结\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"慢查SQL定位与分析","url":"/2023/07/09/%E6%85%A2%E6%9F%A5SQL%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%88%86%E6%9E%90/","content":"慢查询概述定义：查询时间超过指定时间的SQL语句\n影响：数据查询的时间变慢，一方面会影响用户的体验；另一方面在高并发的场景下慢查询会占用数据库连接，查询请求堆积，DB服务器CPU一直占用，严重会导致DB挂了\n出现场景：全表扫描、索引使用不当、复杂SQL语句\n慢查询定位：慢查询日志MySQL中会有一个阈值（默认为10s），在SQL执行过程中，会将运行时间超过该阈值的SQL语句存储到慢查询日志中。因此可以通过该日志定位慢查询SQL\n默认情况下是不开启该日志的，需要手动开启\nmysql&gt; show variables like &#x27;slow_query_log&#x27;;                                                                                                   +----------------+-------+                                                                                                                     | Variable_name  | Value |                                                                                                                     +----------------+-------+                                                                                                                     | slow_query_log | OFF   |                                                                                                                     +----------------+-------+                                                                                                                     1 row in set (0.00 sec) \n\n慢查询日志相关参数long_query_time\n慢查询阈值，默认为10s。在MySQL5.1之后以微秒记录\nlong_query_not_using_indexes\n如果运行的SQL没有使用到索引，MySQL同样会将该SQL语句存储到慢查询日志中\nlong_throttle_queries_not_using_indexes（MySQL5.6.5之后）\n每分钟允许记录到slow log中并未使用索引的SQL语句次数。默认为0，表示不限制\n主要是为了防止slow log过大\nlog_output\n指定慢查询日志的输出格式，默认为FILE。为TABLE时可以在mysql架构下的slow_log中查看\n查看慢查询日志当slow log中记录的慢SQL过多的时候，直接查看不太方便。有两种方式可以解决这个问题：\n使用MySQL提供的mysqldumpslow命令\nroot@iZwz9evxymdqdx56ut6rv0Z:/var/lib/mysql# mysqldumpslow /var/lib/mysql/iZwz9evxymdqdx56ut6rv0Z-slow.log                                                                                                                                                                                    Reading mysql slow query log from /var/lib/mysql/iZwz9evxymdqdx56ut6rv0Z-slow.log                                                              Count: 2  Time=10.00s (20s)  Lock=0.00s (0s)  Rows=1.0 (2), root[root]@localhost                                                                 select sleep(N)      \n\n会对SQL语句中的查询条件参数进行替换，替换后相同的SQL语句看成整体进行统计\n使用slow_log表\nMySQL5.1后可以将慢查询日志记录存放在mysql架构下的slow_log表中\nmysql&gt; show variables like &#x27;log_output&#x27;;                                                                                                       +---------------+-------+                                                                                                                      | Variable_name | Value |                                                                                                                      +---------------+-------+                                                                                                                      | log_output    | FILE  |                                                                                                                      +---------------+-------+                                                                                                                      1 row in set (0.01 sec)                                                                                                                                                                                                                            mysql&gt; set GLOBAL log_output=&#x27;TABLE&#x27;;                                                                                                          Query OK, 0 rows affected (0.00 sec)                                                                                                                                                                                                                                                          mysql&gt; select * from mysql.slow_log;                                                                                                           Empty set (0.01 sec)                                                                                                                                                                                                                                      mysql&gt; select sleep(10);                                                                                                                       +-----------+                                                                                                                                  | sleep(10) |                                                                                                                                  +-----------+                                                                                                                                  |         0 |                                                                                                                                  +-----------+                                                                                                                                  1 row in set (10.00 sec)                                                                                                                                                                                                                                                                      mysql&gt; select sleep(10);                                                                                                                       +-----------+                                                                                                                                  | sleep(10) |                                                                                                                                  +-----------+                                                                                                                                  |         0 |                                                                                                                                  +-----------+                                                                                                                                  1 row in set (10.00 sec)                                                                                                                                                                                                                                                                      mysql&gt; select * from mysql.slow_log;                                                                                                           +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+------------------------------------+-----------+                                                                     | start_time                 | user_host                 | query_time      | lock_time       | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text                           | thread_id |                                                                     +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+------------------------------------+-----------+                                                                     | 2023-07-06 23:59:40.406137 | root[root] @ localhost [] | 00:00:10.000616 | 00:00:00.000000 |         1 |             1 |    |              0 |         0 |         1 | 0x73656C65637420736C65657028313029 |      4220 |                                                                     | 2023-07-06 23:59:51.690646 | root[root] @ localhost [] | 00:00:10.000516 | 00:00:00.000000 |         1 |             1 |    |              0 |         0 |         1 | 0x73656C65637420736C65657028313029 |      4220 |                                                                     +----------------------------+---------------------------+-----------------+-----------------+-----------+---------------+----+----------------+-----------+-----------+------------------------------------+-----------+                                                                     2 rows in set (0.00 sec)  \n\nslow_log是使用CSV存储引擎，对大数据量下的查询效率不高，可以将其更改为MyISAM，同时在start_time列上添加索引（需要先将慢查询关闭）\n逻辑读取 &amp; 物理读取当数据库的容量比较小时，可能由于数据全部被缓存在缓冲池中，导致一些不合格的SQL运行时间比较短，无法记录在slow_log中\nInnoDB增强了对SQL语句的捕获，在slow log中增加了物理读取与逻辑读取\n物理读取：从磁盘IO中进行读取的次数\n逻辑读取：所有的读取\nlong_query_io\n将超过指定逻辑IO次数的SQL语句记录到slow log中，默认为100\nslow_query_type（为了兼容原MySQL）\n0：不将SQL语句记录到slow log\n1：根据运行时间将SQL语句记录到slow log\n2：根据逻辑IO次数将SQL语句记录到slow log\n3：根据运行时间与逻辑IO将SQL记录到slow log\n慢查询分析慢SQL可以从SQL语句结构、使用场景、执行计划三方面进行分析\nSQL语句结构对于SQL结构拆解分析需要理清以下三点：\n\nSQL的结构特点：简单单一查询？join关联查询？子查询？……\nSQL语句关键字可能带来的问题：like模糊匹配、order by&#x2F;group by&#x2F;join使用的驱动表大小、limit高起点的深翻页问题、not in带来的全表扫描问题……\n相关表建立的索引情况\n\n使用场景站在sql语句语法本身之外的角度分析sql的使用方式上，包括但不限如下几点：\n使用的业务场景：\n\n需要支持模糊关键词搜索\n需要多条件的复杂的在线实时查询\n定时任务\n页面查询 or 系统调用\n……\n\n运行的环境：\n\n产生慢sql的应用机器&#x2F;DB实例：预发or线上机器产生的，之前遇到过预发环境工具导致的慢sql问题；是否是同一个DB实例产生慢sql，可能实例磁盘问题或数据倾斜等问题\nsql运行的周期&#x2F;频率&#x2F;时间点：根据周期运行规律可以判断是否为定时任务产生，定时任务有时会捞取大量数据扫全表导致慢sql；其次针对某一时间点的某个特定DB实例造成的慢sql，可以通过DBPaas分析，发现是由于夜间的磁盘抖动造成慢sql，联系DBA确认确实磁盘有问题\n\n分析执行计划要优化慢查询，最重要的是需要知道一条SQL语句的执行需要经历哪些步骤，在哪些步骤可能会存在导致查询时间过长，最后在卡点处进行优化\n一条SQL语句的执行主要分为几个步骤：语法解析&#x3D;&#x3D;》生成执行计划&#x3D;&#x3D;》执行SQL语句&#x3D;&#x3D;》输出结果\n一般的慢查询主要卡点在执行SQL语句这一步，我们需要通过执行计划去分析是怎么执行的，就可以有效帮助我们分析SQL性能差的原因\nSQL性能优化的目标：type至少要达到range级别，要求是ref级别，如果可以最好是const\n慢查询日志分析对于慢查询日志中的每一条SQL语句，主要从以下的几个指标去进行分析：\n\n\n\n参数\n含义\n要点\n\n\n\nquery_time\n查询时间\n默认超过10s会被记录\n\n\nlock_time\n锁表时间\n当该时间占据执行时间的大部分时，要注意锁表的范围、冲突情况等\n\n\nrows_sent\n查询返回的结果条数\n当检查条数较多但是返回条数较少时，通常说明SQL语句可以优化\n\n\nrows_examined\n查询检查的结果条数\n\n\n\nrows_affected\n查询影响的条数\n\n\n\nexplain分析通过explain可以分析SQL语句的执行计划，但是只是表示MySQL可能的执行计划，在实际执行过程中并不是完全按照该计划执行，只有慢查询日志中显示的才是真正的执行计划\n以下是explain执行计划中的每个字段详情：\n\n\n\n参数\n含义\n要点\n\n\n\nid\n查询执行的顺序一般有多少个select（子查询）就有多少个idid越大执行的优先级越高，越先被执行，id相同则从上往下执行，id为null表示最后执行\n\n\n\nselect_type\nSIMPLE：简单查询，不包含子查询和unionPRIMARY：复杂查询中最外层的selectSUBQUERY：包含在select中的子查询DERIVED：包含在from子句中的子查询，结果会存放在临时表中\n\n\n\ntable\n当前查询正在访问的表\n\n\n\ntype\n表示MySQL如何查找表中的行system、const：primary key或unique key与常数比较是，最多只有一个匹配行，读取一次。system是const的特里，表中只有一条数据时为systemeq_ref：primary key或unique key索引的所有部分被连接使用，最多只有一个匹配行ref：使用普通索引或联合索引的部分前缀与值匹配，可能会找到多个符合条件的行range：使用一个索引来检索给定范围的行index：全表扫索引，通过扫描整棵索引树得到结果如果是覆盖索引则Extra为Using indexall：全表扫描\n表现从好到坏是：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all\n\n\npossible_keys\n可能会使用到哪些索引进行查询\npossibles_keys和key均不为空：正常使用索引possibles_key不为空，key为空：通过索引并不能提高查询效率，一般是因为索引字段选择性差或表数据量小possibles_key为空，keys不为空：一般是因为where没有命中索引，但是查询的列是索引字段，命中了覆盖索引\n\n\nkey\n实际使用到的索引\n\n\n\nkey_len\n索引使用到的字节数\n在联合索引中可以用于判断使用到了索引中的哪些列：tinyint：1smallint：2int：4bigint：8data：3timestamp：4datetime：8\n\n\nref\n在key列记录的索引中，表查找值所用到的列或常量\n\n\n\nrows\n估计要读取并检查的行数\n\n\n\nfiltered\n返回结果的行占需要读到的行(rows列的值)的百分比\n\n\n\nextra\n额外的信息Using index：使用覆盖索引Using where：使用where语句处理结果，并且查询的列未被索引覆盖Using index condition：查询的列不完全被索引覆盖，需要回表查询Using temporary：需要使用临时表处理查询Using filesort：使用外部排序而不是索引排序Using tables optimized away：使用某些聚合函数访问存在索引的字段Using join buffer(Block Nested Loop）：使用join buffer(BNL算法）进行关联执行Using MRR(Multi-Range Read)：使用辅助索引进行多范围读\n\n\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"《高性能MySQL》读书笔记查询性能优化","url":"/2023/07/03/%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","content":"一条SQL语句生命周期为：从客户端发送到服务端&#x3D;&#x3D;》服务端进行语法分析&#x3D;&#x3D;》生成执行计划&#x3D;&#x3D;》执行&#x3D;&#x3D;》给客户端返回结果\n执行是整个过程中最主要的阶段，包含对存储引擎的调用获取数据以及调用后的数据处理，如排序、分组等\nSQL语句的在执行主要会会受到CPU、内存、统计信息、执行计划、锁等待等因素的影响\n那么SQL语句的优化就是分析出哪些因素导致时间消耗过多，并进行解决\n一般来说，SQL****语句性能差主要是由于访问数据太多，大部分性能低下的查询都可以通过减少访问数据量的方式进行优化，可以通过两个步骤进行分析：\n\n确定应用程序是否在检索大量且不必要的数据\n比如：\n\n查询多条数据但是分页显示只显示一部分数据\n\n返回全部的列\n\n重复查询相同的列（解决：缓存）\n\n\n\n确定MySQL服务器层是否在分析大量不需要的数据行\n\n⭐⭐⭐通过衡量查询开销的指标进行分析：\n\n响应时间：服务时间（真正执行SQL语句的时间） + 排队时间（等待资源而没有在执行的时间）\n但是目前没办法将响应时间细分在这两部分时间上。判断响应时间是不是一个合理的值目前可以通过：了解这个查询需要哪些索引以及它的执行计划是什么，然后计算大概需要多少个顺序和随机I&#x2F;O，再用其乘以在具体硬件条件下一次I&#x2F;O的消耗时间。最后把这些消耗都加起来，就可以获得一个大概参考值来判断\n\n\n扫描的行数和返回的行数\n返回的行数和访问类型：explain中的type列表示访问类型，如全表扫描、范围扫描、索引扫描等\n\n查询的条件能否使用到索引对于SQL的性能来说至关重要，从好到坏的有以下的方式：\n\n在索引中使用where条件过滤不匹配的记录（存储引擎层完成）\n使用索引覆盖扫描返回记录，直接在索引中过滤不需要的记录并返回命中的结果（服务层完成，但是后面有了索引下推后可以在存储引擎层完成）\n从数据表中返回数据，然后过滤掉不满足的条件（服务层完成）\n\n如果发现查询需要扫描大量的行但只返回少数行时，可以通过以下方法去优化：\n\n使用索引覆盖扫描，把所有需要用的列都放到索引中，这样存储引擎无须回表获取对应行就可以返回结果了\n改变库表结构。例如，使用单独的汇总表\n重写这个复杂的查询，让MySQL优化器能够以更优化的方式执行这个查询\n\n优化有问题的查询时，可以将查询转换一种写法让其返回一样的结果，比如：\n\n一个复杂的查询分成多个简单的查询\n切分查询：对于一个大查询，我们需要“分而治之”，将大查询切分成小查询\n比如定期清除大量数据时，如果用一个大的语句一次性完成的话，则可能需要一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。将一个大的DELETE语句切分成多个较小的查询可以尽可能小地影响MySQL的性能，同时还可以降低MySQL复制的延迟\n\n\n分解联接查询：对每一个表进行一次单表查询，然后将结果在应用程序中进行联接\n优点：\n\n让缓存的效率更高\n\n执行单个查询可以减少锁的竞争\n\n在应用层做联接可以更容易对数据库进行拆分，更容易做到高性能和可扩展\n\n查询本身的效率也会提升\n\n减少对冗余记录的访问：应用层做联接查询，意味着对于某条记录应用只需要查询一次，而在数据库中做联接查询，则可能需要重复地访问一部分数据\n\n\n\n\n对于一个MySQL连接，或者一个线程，任何时刻都有一个状态，该状态表示了MySQL当前正在做什么。可以使用**SHOW FULL PROCESSLIST**命令查看当前的状态：\n\nsleep：线程正在等待客户端发送新的请求\nquery：线程正在执行查询或正在将结果发送给客户端\nlocked：在MySQL服务器层，该线程正在等待表锁。在存储引擎级别实现的锁，例如InnoDB的行锁，并不会体现在线程状态中\nAnalyzing and statistics：线程正在检查存储引擎的统计信息，并优化查询\nCopying to tmp table [on disk]：线程正在执行查询，并且将其结果集复制到一个临时表中。一般是在执行GROUP BY &#x2F; 排序 &#x2F; UNION操作。如果这个状态后面还有“on disk”标记，那表示MySQL正在将一个内存临时表放到磁盘上\nSorting result：线程正在对结果集进行排序。\n\n可以通过状态分析当前MySQL是否有异常\n查询优化器用于找到最好的执行计划\nMySQL使用基于成本的优化器，会预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。最初，成本的最小单位是随机读取一个4KB数据页的成本，后来成本计算公式变得更加复杂，并且引入了一些“因子”来估算某些操作的代价，如执行一次WHERE条件比较的成本。可以通过查询当前会话的Last_query_cost的值来得知MySQL计算的当前查询的成本\n成本是根据一系列的统计信息计算得来的：每个表或者索引的页面个数、索引的基数（索引中不同值的数量）、索引和数据行的长度、索引分布情况。优化器在评估成本的时候并不考虑任何层面的缓存带来的影响，它假设读取任何数据都需要一次磁盘I&#x2F;O\n会有很多种情况导致优化器选择错误的执行计划：\n\n统计信息不准确\n成本指标并不完全等同于运行查询的实际成本。例如，有时候某个执行计划虽然需要读取更多的页面，但是它的成本却更低。因为如果这些页面都是顺序读或者这些页面都已经在内存中的话，那么它的访问成本将很低。因为MySQL并不知道哪些页面在内存中、哪些在磁盘中，所以查询在实际执行过程中到底需要多少次物理I&#x2F;O是无法得知的\nMySQL的最优可能和你想的最优不一样。你可能希望执行时间尽可能短，但是MySQL只是基于其成本模型选择最优的执行计划，而有些时候这并不是最快的执行方式\nMySQL从不考虑其他并发执行的查询，这可能会影响到当前查询的速度\nMySQL并不是任何时候都是基于成本的优化。有时也会基于一些固定的规则，例如，如果存在全文搜索的MATCH()子句，则在存在FULLTEXT索引的时候就使用全文索引。即使有时候使用其他索引和WHERE条件可以远比这种方式要快，MySQL也仍然会使用对应的全文索引\nMySQL不会考虑不受其控制的操作的成本，例如，执行存储函数或者用户自定义函数的成本\n优化器有时候无法估算所有可能的执行计划，所以可能错过实际上最优的执行计划\n\n⭐⭐⭐MySQL能够处理的优化类型：\n\n重新定义联接表的顺序\n将外联转换为内联\n使用代数等价变换规则：MySQL可以使用一些代数等价变换规则来简化并规范表达式。它可以合并和减少一些比较，还可以移除一些恒成立和一些恒不成立的判断\n优化count()\\min()\\max()：索引和列是否可为空通常可以帮助MySQL优化这类表达式。例如，要找到某一列的最小值，只需要查询对应B-tree索引最左端的记录，MySQL可以直接获取索引的第一行记录。在B-tree索引中，优化器会将这个表达式作为一个常数对待。如果MySQL使用了这种类型的优化，那么在EXPLAIN中就可以看到“Select tables optimized away”，表示优化器已经从执行计划中移除了该表，并以一个常数代替\n预估并转换为常数表达式：当MySQL检测到一个表达式可以转化为常数的时候，就会一直把该表达式作为常数进行优化处理\n索引覆盖扫描\n子查询优化：MySQL在某些情况下可以将子查询转换为一种效率更高的形式，从而减少多个查询多次对数据进行访问\n提前终止查询：在发现已经满足查询需求的时候，MySQL总是能够立刻终止查询。比如limit时\n等值传播：如果两列的值可通过等式联接，那么MySQL能够把其中一列的WHERE条件传递到另一列上\n列表IN()的比较：在很多数据库服务器中，IN()完全等同于多个OR条件的子句，因为这两者是完全等价的。在MySQL中这点是不成立的，MySQL将IN()列表中的数据先进行排序，然后通过二分查找的方式来确定列表中的值是否满足条件，这是一个O(logn)复杂度的操作，等价地转换成OR查询的复杂度为O(n)，对于IN()列表中有大量取值的时候，MySQL的处理速度将会更快\n……\n\n联接查询优化器MySQL****的联接执行策略：MySQL对任何联接都执行嵌套循环联接操作，即MySQL先在一个表中循环取出单条数据，然后再嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为止。最后根据各个表匹配的行，返回查询中需要的各列。MySQL会尝试在最后一个联接表中找到所有匹配的行，如果最后一个联接表无法找到更多的行，MySQL返回到上一层次的联接表，看是否能够找到更多的匹配记录，依此类推，迭代执行。在MySQL 8.0.20版本之后，已经不再使用基于块的嵌套循环联接操作，取而代之的是哈希联接。这让联接操作性能变得更好，特别是当数据集可以全部存储在内存时。\n联接优化器会尝试在所有的联接顺序中选择一个成本最低的来生成执行计划树：\n如果可能，优化器会遍历每一个表，然后逐个做嵌套循环，计算执行每一棵可能的计划树的成本，最后返回一个最优的执行计划\n不过，糟糕的是，n个表的联接可能有n的阶乘种联接顺序，我们称之为所有可能的查询计划的“搜索空间”\n当搜索空间非常大的时候，优化器不可能逐一评估每一种联接顺序的成本。这时，优化器选择使用“贪婪”搜索的方式查找“最优”的联接顺序\n当需要联接的表超过optimizer_search_depth的限制的时候，就会选择“贪婪”搜索模式了（optimizer_search_depth参数可以根据需要指定大小）。在MySQL这些年的发展过程中，优化器积累了很多“启发式”的优化策略来加速执行计划的生成\n⭐⭐⭐排序优化如果需要排序的数据量小于“排序缓冲区”，MySQL使用内存进行快速排序操作。如果内存不够排序，那么MySQL会先将数据分块，对每个独立的块使用“快速排序”进行排序，并将各个块的排序结果存放在磁盘上，然后将各个排好序的块进行合并(merge)，最后返回排序结果\nMySQL****有两种排序算法：\n\n两次传输排序（旧版本）\n读取行指针和需要排序的字段，对其进行排序，然后再根据排序结果读取所需要的数据行\n\n需要进行两次数据传输，即需要从数据表中读取两次数据，第二次读取数据的时候，因为是读取排序列进行排序后的所有记录，这会产生大量的随机I&#x2F;O，所以两次传输排序的成本非常高\n\n\n\n单次传输排序（新版本）\n先读取查询所需要的所有列，然后再根据给定列进行排序，最后直接返回排序结果\n\n只需要一次顺序I&#x2F;O就可读取所有的数据，而无须任何的随机I&#x2F;O\n\n可能占用更多空间，因为会保存查询中每一行所需要的列。这意味着更少的数据可以放入排序缓冲区，使得文件排序(filesort)操作必须执行更多的排序合并过程。\n\n\n\n\n如果联接查询种需要排序：\n\n如果ORDER BY子句中的所有列都来自联接的第一个表，那么MySQL在联接处理第一个表的时候就进行文件排序。在MySQL的EXPLAIN结果中可以看到Extra字段会有“Using filesort”字样\n除此之外的所有情况，MySQL都会先将联接的结果存放到一个临时表中，然后在所有的联接都结束后，再进行文件排序。在这种情况下，在MySQL的EXPLAIN结果的Extra字段可以看到“Using temporary；Using filesort”字样。如果查询中有LIMIT的话，LIMIT也会在文件排序之后应用，所以即使需要返回较少的数据，临时表和需要排序的数据量仍然会非常大\n\n查询优化器的局限性UNION的限制\n有时，MySQL无法将限制条件从UNION的外层“下推”到内层，这使得原本能够限制部分返回结果的条件无法应用到内层查询的优化上\n如果希望UNION的各个子句能够根据LIMIT只取部分结果集，或者希望能够先排好序再合并结果集的话，就需要在UNION的各个子句中分别使用这些子句\n例如：\n想将两个子查询结果联合起来，然后再取前20条记录，那么MySQL会将两个表存放到同一个临时表中，然后再取出前20行记\n可以通过在UNION的两个子查询中分别加上一个LIMIT来减少临时表中的数据\n但是从临时表中取出数据的顺序并不是一定的，所以如果想获得正确的顺序，还需要在最后的LIMIT操作前加上一个全局的ORDER BY操作\n等值传递\n某些时候，等值传递会带来一些意想不到的额外消耗。例如，考虑一列上的巨大IN()列表，优化器知道它将等于其他表中的一些列，这是由于WHERE、ON或USING子句使列彼此相等。优化器通过将列表复制到所有相关表中的相应列来“共享”列表。通常，因为各个表新增了过滤条件，所以优化器可以更高效地从存储引擎过滤记录。但是如果这个列表非常大，则会导致优化和执行都会变慢。在写作本书的时候，除了修改MySQL源代码，目前还没有什么办法能够绕过该问题（不过这个问题很少会碰到）\n并行执行\nMySQL无法利用多核特性来并行执行查询\n在同一个表中查询和更新\nMySQL不允许对一张表同时进行查询和更新\n","categories":["MySQL"],"tags":["读书笔记"]},{"title":"《高性能MySQL》读书笔记表的设计与管理","url":"/2023/07/01/%E8%A1%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E7%AE%A1%E7%90%86/","content":"选择优化的数据类型MySQL支持的数据类型非常多，选择正确的数据类型对于获得高性能至关重要\n选择原则：\n\n更小的通常更好：尽量使用能够正确存储和表示数据的最小数据类型，占用的空间更少，处理需要的CPU周期更少\n简单为好：简单的数据类型处理所需的CPU周期比较少\n整型数据比字符型数据的比较操作代价更低，因为字符集和排序规则(collation)使字符型数据的比较更复杂\n将日期和时间存储为MySQL的内置类型而不是字符串类型\n用整型数据存储IP地址\n\n\n尽量避免存储****NULL：NULL的列使索引、索引统计和值比较都更复杂，且NULL的列会占用更多的存储空间\n但是在调优时将NULL改为NOT NULL带来的性能提升比较小\n\n\n\n选择步骤：\n\n确定合适的大类型：数字、字符串、时间等\n选择具体类型：MySQL数据类型很多可以存储相同类型的数据，但是在存储的值范围、精度、占据空间上有着不同\n\n整数类型MySQL中整数有以下几种类型：\n\nTINYINT：8位，存储值范围：-2$$^7 $$~ 2$$^7$$-1\nSMALLINT：16位，存储值范围：-2$$^{15}  $$~ 2$$^{15} $$-1\nMEDIUMINT：24位，存储值范围：-2$$^{23}  $$~ 2$$^{23} $$-1\nINT：32位，存储值范围：-2$$^{31}  $$~ 2$$^{31} $$-1\nBIGINT：64位，存储值范围：-2$$^{63} $$~ 2$$^{63} $$-1\n\n整数类型有可选的UNSIGNED属性，表示不允许负值，这大致可以使正数的上限提高一倍。例如，TINYINT UNSIGNED可以存储的值的范围是0～255，而TINYINT的值的存储范围是-128～127\n不同的整数类型占据的空间是不同的，但是整数计算通常使用BIGINT，除了一些聚合函数\n同时MySQL可以为整数类型指定宽度，比如INT(11)，但是不会限制值的范围，依旧是32位，例如INT(11)和INT(20)是相同的，只是规定了MySQL的一些交互工具中用于显示字符的个数\n实数类型MySQL中实数有以下几种类型：\n\nDECIMAL：提供精确类型\nFLOAT &amp; DOUBLE：不精确，是近似计算，前者占据4字节，后者占据8字节\n\nMySQL中我们可以选择不同的实数类型，但是浮点类型的内部计算是使用DOUBLE\n注意：DECIMAL由于精确计算需要额外的空间和计算成本，性能要求比较高。建议只在需要精确计算的时候才使用。同时对于一些大容量场景，可以考虑用BIGINT代替DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可。假设要存储财务数据并精确到万分之一分，则可以把所有金额乘以一百万，然后将结果存储在BIGINT里，这样可以同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题\n字符串类型MySQL支持多种字符串数据类型，每种类型还有许多变体。每个字符串列可以有自己的字符集和该字符集的排序规则集\nVARCHAR &amp; CHAR在磁盘和内存中的存储方式在不同的存储引擎下是不同的，下面以InnoDB为准。同时同种存储引擎在内存中存储二者的方式可能和磁盘上存储方式不同\nVARCHAR用于存储可变长度的字符串\n会额外使用字节记录字符串的长度：\n\n列的长度&lt;&#x3D;255字节：用1字节表示\n列的长度&gt;255字节：用2字节表示\n\n优点：只使用必要的空间，所以比固定长度的类型更加节省空间\n缺点：行是可变长度，在更新时可能会增长，会导致额外的工作。如果行的增长使原位置无法容纳更多内容，不同存储引擎处理方式不同。InnoDB可能需要分割页面来容纳行，其他存储引擎可能不在原数据位置更新数据\n使用场景：\n\n字符串列的最大长度远大于平均长度\n列的更新少\n使用类似UTF-8的复杂字符集，每个字符都用不同的字节数存储\n\nvarchar分配是否越多越好？比如使用varchar(5)和varchar(200)存储’hello’的空间开销是一样的，那么使用更短的列有什么优势？\n较大的列会使用更多的内存，MySQL会在内部分配固定大小的内存块保存值，也就是按照最长的方式在内存中分配空间。比如排序是varchar(200)是按照200这个长度来进行的，不合理的长度会浪费空间。\n所以最合理的策略是按需分配\nCHAR是固定长度的，MySQL会为定义的字符串长度分配足够的空间。当存储CHAR值时，MySQL删除所有尾随空格。如果需要进行比较，值会用空格填充\n使用场景：\n\n所有值的长度几乎都相同的情况（比如用户密码的MD5值）\n经常修改的数据（不易出现碎片）\n非常短的列（varchar还需要额外的字节记录长度）\n\nBLOB &amp; TEXT用于存储很大的数据，分别用于二进制存储与字符方式存储\n当BLOG &amp; TEXT的值太大是，InnoDB会使用外部存储区域进行存储，此时每个值在行内只需要记录外部存储区域的地址即可\n排序方式：只对列的最前max_sort_length字节排序，而不是整个字符串\nMySQL不能将BLOB和TEXT数据类型的完整字符串放入索引，也不能使用索引进行排序\n一般不建议使用BLOB或TEXT存储类似图像等数据，会导致表过大同时修改查询表这些操作变慢。一般是使用单独的对象数据存储，然后在表中跟踪对应的位置或文件名（类似文件存储在fastDFS中，然后在MySQL表中记录文件在FastDFS中的位置）\n使用枚举代替字符串类型ENUM列可以存储一组预定义的不同字符串值，MySQL在存储枚举时用会整数进行表示，而不是字符串，使得占用空间压缩到1~2字节\nCREATE TABLE enum_test(    e ENUM(&#x27;fish&#x27;,&#x27;apple&#x27;,&#x27;dog&#x27;) NOT NULL);INSERT INTO enum_test(e) VALUES(&#x27;fish&#x27;),(&#x27;dog&#x27;),(&#x27;apple&#x27;);mysql&gt; select * from enum_test;                                                                                                                +-------+                                                                                                                                      | e     |                                                                                                                                      +-------+                                                                                                                                      | fish  |                                                                                                                                      | dog   |                                                                                                                                      | apple |                                                                                                                                      +-------+                                                                                                                                      3 rows in set (0.00 sec)                                                                                                                                                                                                                                                                      mysql&gt; select e + 0 from enum_test;                                                                                                            +-------+                                                                                                                                      | e + 0 |                                                                                                                                      +-------+                                                                                                                                      |     1 |                                                                                                                                      |     3 |                                                                                                                                      |     2 |                                                                                                                                      +-------+                                                                                                                                      3 rows in set (0.00 sec) \n\nenum字段是根据内部整数值排序的，而不是根据字符串\nmysql&gt; select e from enum_test order by e;                                                                                                     +-------+                                                                                                                                      | e     |                                                                                                                                      +-------+                                                                                                                                      | fish  |                                                                                                                                      | apple |                                                                                                                                      | dog   |                                                                                                                                      +-------+                                                                                                                                      3 rows in set (0.00 sec)  \n\n可以通过按照需要的顺序指定ENUM成员来解决这个问题。也可以在查询中使用FIELD()函数显式地指定排序顺序，但这会导致MySQL无法利用索引消除排序\nmysql&gt; select e from enum_test order by FIELD(e,&#x27;apple&#x27;,&#x27;dog&#x27;,&#x27;fish&#x27;);                                                                         +-------+                                                                                                                                      | e     |                                                                                                                                      +-------+                                                                                                                                      | apple |                                                                                                                                      | dog   |                                                                                                                                      | fish  |                                                                                                                                      +-------+                                                                                                                                      \n\nMySQL将枚举值存储为整数，在查找时需要根据整数去获取对应的字符串。这一部分的开销通常可以被enum列的小尺寸所抵消\n使用时需要考虑的地方：\n\nenum值是否会过多\nenum值是否需要经常修改（会导致表经常变更）\n\n日期和时间类型MySQL提供了两种类型用于实现同时存储日期和时间\nDATETIME可以保存大范围的数值，从1000年到9999年，精度为1微秒。它以YYYYMMDDHHMMSS格式存储压缩成整数的日期和时间，且与时区无关。这需要8字节的存储空间\n可排序、无歧义\nTIMESTAMP存储自1970年1月1日格林尼治标准时间(GMT)午夜以来经过的秒数——与UNIX时间戳相同。TIMESTAMP只使用4字节的存储空间，所以它的范围比DATETIME小得多：只能表示从1970年到2038年1月19日。时间戳显示的值依赖于时区\n默认情况下，当插入&#x2F;更新一行记录时没有指定第一个TIMESTAMP列的值，MySQL会将该列的值设置为当前时间\n使用时的考虑因素\n都需要处理服务器和客户端上的时区问题\nTIMESTAMP会有2038年限制\n存储空间\n时间精度\n\n通过将日期和时间存储为UNIX纪元（即自1970年1月1日以来的秒数），以协调世界时(UTC)的形式，可避免MySQL处理的复杂性，这一做法越来越流行。使用带符号的32位INT，可以表达直到2038年的时间。使用无符号的32位INT，可以表达直到2106年的时间。如果使用64位，还可以超出这些范围\n特殊数据类型某些类型的数据并不直接对应于可用的内置类型。IPv4地址就是一个很好的例子。人们通常使用VARCHAR(15)列来存储IP地址。然而，它们实际上是32位无符号整数，而不是字符串。用小数点将地址分成四段的表示方法只是为了让人们阅读容易，所以应该将I P地址存储为无符号整数。MySQL提供了INET_ATON()和INET_NTOA()函数来在这两种表示形式之间进行转换。使用的空间从VARCHAR(15)的约16字节缩减到无符号32位整数的4字节。如果你担心数据库的可读性，不想继续使用函数查看行数据，请记住MySQL有视图，可以使用视图来简化数据查看的复杂性。\nSchema设计陷阱\n太多的列：服务器在转换行格式时会消耗过大的CPU\n太多的联接\n过度使用枚举\n警惕NULL值\n上面已经讲过避免使用NULL\n当需要表示未知值时，不要太害怕使用NULL。在某些情况下，使用NULL比使用某个虚拟常数更好。避免使代码复杂化，引入bug。例如DATETIME设置为0000-00-00 00:00:00可能会导致一些问题\n\n\n\n","categories":["MySQL"],"tags":["读书笔记"]},{"title":"设计模式","url":"/2023/04/30/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"设计模式是指在软件开发中，经过验证的，用于解决在特定环境下，重复出现的，特定问题的解决方案\n按照设计目的分为三类：创建型模式、结构型模式和行为模式\n分别对应了面向对象开发的三个问题：如何创建对象、如何组合对象、如何处理对象之间的动态通信和职责分配\n设计原则单一职责在设计类的时候要尽量缩小粒度，使功能明确、单一，不要做多余的事情（高内聚，低耦合）\n单一职责下的类会比较小而精悍，需要使用结构性模式组合复用他们\n开闭原则一个类应该对扩展开发，对修改关闭\n关键是要做好封装，隐藏内部的实现细节，开发足够的接口，这样子外部的代码就只能通过接口去扩展功能，不需要侵入到类的内部\nfinal关键字\n不能说要实现某个功能必要要修改类内部的代码才能实现，需要能够通过扩展实现新的功能（低耦合）\n里氏替换子类能够完全替换父类，不会改变父类定义的行为\n比如一个基类鸟类中有一个方法，能够飞行，所有的鸟类都必须继承它，但是企鹅、鸵鸟这些没办法飞行（使用接口代替继承）\n接口隔离不应该强迫客户依赖于它们不需要的接口\n建立单一接口，不要建立庞大的接口，尽量细化，接口中的方法要建立少\n类“犬科”依赖接口I中的方法：捕食（），行走（），奔跑（）， 宠物狗类是对类“犬科”的实现。 对于具体的类：宠物狗来说，虽然存在着用不到的方法，但由于继承了接口，所以也必须要实现这些用不到的方法\n依赖倒置上层要避免依赖下层的实现细节，两者都应该依赖于抽象\n比如Java的操作数据库，Java定义了一组接口，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承继承耦合度高，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传入不同的类，避免高耦合\n设计模式单例模式保证一个类仅有一个实例，并提供一个该实例的全局访问点\n版本一class Singleton1 &#123;public:    static Singleton1* GetInstance() &#123;        if (instance == nullptr) &#123;            instance = new Singleton1();        &#125;        return instance;    &#125;private:    // 防止外界构造和删除对象    Singleton1() = default;    ~Singleton1() = default;    Singleton1(const Singleton1&amp;) = default;    Singleton1&amp; operator=(const Singleton1&amp;) = default;    static Singleton1 *instance;&#125;;Singleton1* Singleton1::instance = nullptr;\n\n存在内存泄露问题，instance是在堆上的，需要手动释放，但是外界没办法调用delete释放对象\n线程安全问题，可能会有多个线程同时分配内存\n版本二class Singleton2 &#123;public:    static Singleton2* GetInstance() &#123;        if (instance == nullptr) &#123;            instance = new Singleton2();            atexit(Destructor); // 在程序退出的时候释放        &#125;        return instance;    &#125;private:    // 防止外界构造和删除对象    Singleton2() = default;    ~Singleton2() = default;    Singleton2(const Singleton2&amp;) = default;    Singleton2&amp; operator=(const Singleton2&amp;) = default;    static void Destructor() &#123;        if (instance != nullptr) &#123;            delete instance;            instance = nullptr;        &#125;    &#125;    static Singleton2 *instance;&#125;;Singleton2* Singleton2::instance = nullptr;\n\n解决了内存泄露问题\n版本三class Singleton3 &#123;public:    static Singleton3* GetInstance() &#123;        if (instance == nullptr) &#123;            lock_guard&lt;mutex&gt; lock(mutex_);            if (instance == nullptr) &#123;                instance = new Singleton3();                atexit(Destructor);            &#125;        &#125;        return instance;    &#125;private:    // 防止外界构造和删除对象    Singleton3() = default;    ~Singleton3() = default;    Singleton3(const Singleton3&amp;) = default;    Singleton3&amp; operator=(const Singleton3&amp;) = default;    static void Destructor() &#123;        if (instance != nullptr) &#123;            delete instance;            instance = nullptr;        &#125;    &#125;    static Singleton3 *instance;    static mutex mutex_;&#125;;Singleton3* Singleton3::instance = nullptr;\n\nnew的时候的操作分为三步：分配内存、调用构造函数、返回指针\n有可能先返回指针当还没有调用构造函数导致对象没有初始化，其他线程获取到没有初始化的对象\n版本四class Singleton4 &#123;public:    static Singleton4* GetInstance() &#123;        Singleton4* tmp = instance.load(std::memory_order_relaxed);        atomic_thread_fence(std::memory_order_acquire); // 获取内存屏障        if (tmp == nullptr) &#123;            lock_guard&lt;mutex&gt; lock(mutex_);            tmp = instance.load(memory_order_relaxed);            if (tmp == nullptr) &#123;                tmp = new Singleton4;                atomic_thread_fence(std::memory_order_release); // 释放内存屏障                instance.store(tmp,memory_order_relaxed);                atexit(Destructor);            &#125;        &#125;        return tmp;    &#125;private:    // 防止外界构造和删除对象    Singleton4() = default;    ~Singleton4() = default;    Singleton4(const Singleton4&amp;) = default;    Singleton4&amp; operator=(const Singleton4&amp;) = default;    static void Destructor() &#123;        if (instance != nullptr) &#123;            delete instance;            instance = nullptr;        &#125;    &#125;    static atomic&lt;Singleton4*&gt; instance;    static mutex mutex_;&#125;;atomic&lt;Singleton4*&gt; Singleton4::instance;mutex Singleton4::mutex_;\n\n版本五 c++11 magic static 特性：如果当变量在初始化的时候，并发同时进⼊声明语句，并发线程将 会阻塞等待初始化结束\nclass Singleton5 &#123;public:    static Singleton5&amp; GetInstance() &#123;        static Singleton5 instance;        return instance;    &#125;private:    Singleton5() = default;    ~Singleton5() = default;    Singleton5(const Singleton5&amp;) = default;    Singleton5&amp; operator=(const Singleton5&amp;) = default;&#125;;\n\n版本六template&lt;typename T&gt;class Singleton6 &#123;public:    static T&amp; GetInstance() &#123;        static T instance;        return instance;    &#125;protected:    virtual ~Singleton6() = default;    Singleton6() = default;    Singleton6(const Singleton6&amp;) = default;    Singleton6&amp; operator=(const Singleton6&amp;) = default;&#125;;class DesignPattern : public Singleton6&lt;DesignPattern&gt; &#123;    friend class Singleton6&lt;DesignPattern&gt;;public:    ~DesignPattern() = default;    private:    DesignPattern() = default;    DesignPattern(const DesignPattern&amp;) = default;    DesignPattern&amp; operator=(const DesignPattern&amp;) = default;&#125;;int main() &#123;    DesignaPattern &amp;d1 = new DesignaPattern::getInstance();&#125;\n\n\n\n模板方法定义一个操作中的算法的骨架 ，但将一些步骤延迟到子类中。 Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤\n本质：通过固定算法骨架约束子类的行为\n理解：只是定义了一个模板是什么样子，但是具体怎么实现交给子类去实现\n背景某个品牌动物园，有一套固定的表演流程，但是其中有若干个表演子流程可创新替换，以尝试迭代 更新表演流程\n#include &lt;iostream&gt;using namespace std;class Zoo &#123;public:    void show() &#123;        show1();        show2();        show3();    &#125;protected:    virtual void show1() &#123;        cout &lt;&lt; &quot;Zoo:show1()&quot; &lt;&lt; endl;    &#125;    virtual void show2() &#123;        cout &lt;&lt; &quot;Zoo:show2()&quot; &lt;&lt; endl;    &#125;    virtual void show3() &#123;        cout &lt;&lt; &quot;Zoo:show3()&quot; &lt;&lt; endl;    &#125;&#125;;class Zoo1 : public Zoo &#123;private:    virtual void show1() &#123;        cout &lt;&lt; &quot;Zoo1:show0()&quot; &lt;&lt; endl;    &#125;    virtual void show2() &#123;        cout &lt;&lt; &quot;Zoo1:show1()&quot; &lt;&lt; endl;    &#125;    virtual void show3() &#123;        cout &lt;&lt; &quot;Zoo1:show3()&quot; &lt;&lt; endl;    &#125;&#125;;int main() &#123;    Zoo* zoo = new Zoo1;    zoo-&gt;show();    return 0;&#125;\n\n\n\n观察者模式定义对象间的一种一对多（变化）的依赖关系，以便当一个对象(Subject)的状态发生改变时，所有依赖于它的对象都得到通知并自动更新\n要求：\n\n独立地改变目标与观察者，从而使二者之间的关系松耦合\n观察者自己决定是否订阅通知，目标对象并不关注谁订阅了\n观察者不要依赖通知顺序，目标对象也不知道通知顺序\n\n背景气象站发布气象资料给数据中心，数据中心经过处理，将气象信息更新到两个不同的显示终端（A 和B）；\n上层：气象站\n下层：显示中断\n依赖：数据中心\n#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class IDisplay &#123;public:    virtual void show(float temperature) = 0;    virtual ~IDisplay() = default;&#125;;class IDisplayA : public IDisplay &#123;public:    virtual void show(float temperature);&#125;;class IDisplayB : public IDisplay &#123;public:    virtual void show(float temperature);&#125;;class WeatherData &#123;&#125;;class DataCenter &#123;public:    void Attach(IDisplay *ob);    void Detach(IDisplay *ob);    void Notify() &#123;        float temper = CalcTemperature();        for (auto iter = obs.begin(); iter != obs.end(); iter++) &#123;            (*iter)-&gt;show(temper);        &#125;    &#125;private:    virtual WeatherData* GetWeatherData();    virtual float CalcTemperature() &#123;        WeatherData *data = GetWeatherData();        float temper;        return temper;    &#125;    vector&lt;IDisplay*&gt; obs;&#125;;int main() &#123;    DataCenter *center = new DataCenter;    IDisplay *da = new IDisplayA;    IDisplay *db = new IDisplayB;    center-&gt;Attach(da);    center-&gt;Attach(db);    center-&gt;Notify();&#125;\n\n\n\n策略模式定义一系列算法，把它们一个个封装起来，并且使它们可互相替换。该模式使得算法可独立于使用它的客户程序而变化\n要点：\n策略模式提供了一系列可重用的算法，从而可以使得类型在运⾏时方便地根据需要在各个算法之间 进行切换（分离算法，选择实现）\n策略模式消除了条件判断语句；也就是在解耦合\n背景某商场节假日有固定促销活动，为了加大促销力度，现提升国庆节促销活动规格\nclass Context &#123;&#125;;class ProStategy &#123;public:    virtual double CalcPro(const Context &amp;ctx) = 0;    virtual ~ProStategy() = default;&#125;;class VAC_Spring : public ProStategy &#123;public:    virtual double CalcPro(const Context &amp;ctx) &#123;&#125;&#125;;class VAC_QIXI : public ProStategy &#123;public:    virtual double CalcPro(const Context &amp;ctx) &#123;&#125;&#125;;class Promotion &#123;public:    Promotion(ProStategy *sss) : s(sss) &#123;&#125;    ~Promotion()&#123;&#125;    double CalcPromotion(const Context &amp;ctx) &#123;        return s-&gt;CalcPro(ctx);    &#125;private:    ProStategy *s;&#125;;int main() &#123;    Context ctx;    ProStategy *s = new VAC_QIXI();    ProStategy *s1 = new VAC_Spring();    Promotion *p = new Promotion(s);    p-&gt;CalcPromotion(ctx);    p = new Promotion(s1);    p-&gt;CalcPromotion(ctx);        return 0;&#125;\n\n\n\n工厂方法定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method使得一个类的实例化延迟到子类\n场景：\n\n比如连接池、线程池\n隐藏对象真实类型\n对象创建会有很多参数来决定如何创建\n创建对象有复杂的依赖关系\n\n背景实现一个导出数据的接口，让客户选择数据的导出方式\nclass IExport &#123;&#125;;class ExportXml : public IExport &#123;&#125;;class IExportFactory &#123;public:    virtual IExport *newExport() = 0;&#125;;class ExportXmlFactory : public IExportFactory &#123;public:    IExport *NewExport() &#123;        IExport *temp = new ExportXml;        return temp;    &#125;&#125;;class ExportData &#123;public:    ExportData(IExportFactory *factory) : factory(factory) &#123;&#125;    ~ExportData() &#123;        if (factory) &#123;            delete factory;            factory = nullptr;        &#125;    &#125;    bool Export(const std::string &amp;data) &#123;        IExport *e = factory-&gt;newExport();        e-&gt;Export(data);    &#125;private:    IExportFactory *factory;&#125;;int main() &#123;    ExportData ed(new ExportXmlFactory);    ed.Export(&quot;hello&quot;);&#125;\n\n将工厂传递给需要的对象，又工厂去创建对象，传入不同的工厂就可以创建不同的对象\n抽象工厂提供一个接口，让该接口负责创建一系列“相关或者相互依赖的对象”，无需指定它们具体的类\n背景如果业务涉及的类越来越多，使用工厂方法每一个子类都需要对应一个工厂，太复杂\n业务中需要创建口罩、防毒面具、防护服这三种产品，而每一种产品有包含高端和低端两类，按照工厂方法模式的解决方案需要创建六个工厂\n\n可以对类进行分类，将口罩分为高端以及低端，每组中的不同产品，由同一个工厂类的不同方法创建\n\n代码实现简化为有口罩和防护服两个抽象接口，分别拥有高端和低端两个实现类\n#include &lt;iostream&gt;using namespace std;// 产品class IMask &#123;public:    virtual void showMask() = 0;&#125;;class LowMask : public IMask &#123;public:    virtual void showMask() &#123;        cout &lt;&lt; &quot;低端口罩&quot; &lt;&lt; endl;    &#125;&#125;;class HighMask : public IMask &#123;public:    virtual void showMask() &#123;        cout &lt;&lt; &quot;高端口罩&quot; &lt;&lt; endl;    &#125;&#125;;class ISuit &#123;public:    virtual void showSuit() = 0;&#125;;class LowSuit : public ISuit &#123;public:    virtual void showSuit() &#123;        cout &lt;&lt; &quot;低端防护服&quot; &lt;&lt; endl;    &#125;&#125;;class HighSuit : public ISuit &#123;public:    virtual void showSuit() &#123;        cout &lt;&lt; &quot;高端防护服&quot; &lt;&lt; endl;    &#125;&#125;;// 工厂class IFactory &#123;public:    virtual IMask* createMask() = 0;    virtual ISuit* createSuit() = 0;&#125;;class LowFactory : public IFactory &#123;public:    virtual IMask* createMask() &#123;        IMask *mask = new LowMask();        return mask;    &#125;    virtual ISuit* createSuit() &#123;        ISuit* suit = new LowSuit();        return suit;    &#125;&#125;;class HightFactory : public IFactory &#123;public:    virtual IMask* createMask() &#123;        IMask* mask = new HighMask();        return mask;    &#125;    virtual ISuit* createSuit() &#123;        ISuit* suit = new HighSuit();        return suit;    &#125;&#125;;int main() &#123;    IFactory* factory1 = new LowFactory();    IFactory* factory2 = new HightFactory();    IMask *mask1 = factory1-&gt;createMask();    IMask *mask2 = factory2-&gt;createMask();    ISuit *suit1 = factory1-&gt;createSuit();    ISuit *suit2 = factory2-&gt;createSuit();    mask1-&gt;showMask();    mask2-&gt;showMask();    suit1-&gt;showSuit();    suit2-&gt;showSuit();    return 0;&#125;\n\n也就是说将产品分类，然后不同类有不同的工厂，在工厂里面生产不同的商品\n区别简单工厂模式：\n简单工厂模式有唯一的工厂类，工厂类的创建方法根据传入的参数做if-else条件判断，决定最终创建什么样的产品对象\n（需要修改代码，违法了开闭原则）\n工厂方法模式：\n工厂方法模式由多个工厂类实现工厂接口，利用多态来创建不同的产品对象，从而避免了冗长的if-else条件判断\n抽象工厂模式：\n抽象工厂模式把产品子类进行分组，同组中的不同产品由同一个工厂子类的不同方法负责创建，从而减少了工厂子类的数量\n","categories":["设计模式"],"tags":["设计模式"]},{"title":"红黑树vs平衡二叉树 & B+树vsB树vs跳表","url":"/2023/06/06/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"数据结构BST树（二叉搜索树）性质\n如果左子树不为空，那么左子树上所有节点的值都小于当前节点\n如果右子树不为空，那么右子树上所有节点的值都大于当前节点\n\nAVL树（平衡二叉树）性质在BST树的基础上引入了平衡因子的概念，要求任意一个节点的左右子树高度差不超过1\n需要旋转的四种情况\n左孩子左子树太高：右旋\n右孩子右子树太高：左旋\n左孩子右子树太高：先对左孩子左旋，再对当前节点右旋（左平衡）\n右孩子左子树太高：先对右孩子右旋，再对当前节点左旋（右平衡）\n\n#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;algorithm&gt;using namespace std;// 定义节点类型template&lt;typename T&gt;struct Node &#123;    Node(T data = T()) : data_(data), left_(nullptr), right_(nullptr), height_(1) &#123;&#125;    T data_;    Node* left_;    Node* right_;    int height_; // 记录节点的高度&#125;;// AVL树template&lt;typename T&gt;class AVLTree &#123;public:    AVLTree() : root_(nullptr) &#123;&#125;    // 插入    void insert(const T&amp; val) &#123;        root_ = insert(root_,val);    &#125;    // 删除    void remove(const T&amp; val) &#123;        root_ = remove(root_,val);    &#125;private:    Node&lt;T&gt;* root_; // 根节点    // 返回节点的高度    int height(Node&lt;T&gt; *node) &#123;        return node == nullptr ? 0 : node-&gt;height_;    &#125;    // 右旋    Node&lt;T&gt;* rightRotate(Node&lt;T&gt;* node);    // 左旋    Node&lt;T&gt;* leftRotate(Node&lt;T&gt;* node);    // 左平衡    Node&lt;T&gt;* leftBalance(Node&lt;T&gt;* node);    // 右平衡    Node&lt;T&gt;* rightBalance(Node&lt;T&gt;* node);    // 插入    Node&lt;T&gt;* insert(Node&lt;T&gt;* node, const T&amp; val);    // 删除    Node&lt;T&gt;* remove(Node&lt;T&gt;* node, const T&amp; val);&#125;;// 右旋template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::rightRotate(Node&lt;T&gt;* node) &#123;    // 节点旋转    Node&lt;T&gt;* child = node-&gt;left_;    node-&gt;left_ = child-&gt;right_;    child-&gt;right_ = node;    // 高度更新    node-&gt;height_ = max(height(node-&gt;left_), height(node-&gt;right_)) + 1;    child-&gt;height_ = max(height(child-&gt;left_), height(child-&gt;right_)) + 1;    // 返回旋转后的子树的新根节点    return child;&#125;// 左旋template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::leftRotate(Node&lt;T&gt;* node) &#123;    // 节点旋转    Node&lt;T&gt; *child = node-&gt;left_;    node-&gt;right_ = child-&gt;left_;    child-&gt;left_ = node;    // 高度更新    node-&gt;height_ = max(height(node-&gt;left_), height(node-&gt;right_)) + 1;    child-&gt;height_ = max(height(child-&gt;left_), height(child-&gt;right_)) + 1;    // 返回旋转后的子树的新根节点    return child;&#125;// 左平衡 先对node的左子树左旋，再对node右旋template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::leftBalance(Node&lt;T&gt; *node) &#123;    node-&gt;left_ = leftRotate(node-&gt;left_);    return rightRotate(node);&#125;// 右平衡 先对node的右子树右旋，再对node左旋template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::rightBalance(Node&lt;T&gt; *node) &#123;    node-&gt;right_ = rightRotate(node-&gt;right_);    return leftRotate(node);&#125;// 插入template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::insert(Node&lt;T&gt; *node, const T &amp;val) &#123;    // 递归结束 找到插入的位置    if (node == nullptr) return new Node&lt;T&gt;(val);    if (node-&gt;data_ &gt; val) &#123;        node-&gt;left_ = insert(node-&gt;left_,val);        // 判断是否失衡        if (height(node-&gt;left_) - height(node-&gt;right_) &gt; 1) &#123;            if (height(node-&gt;left_-&gt;left_) &gt;= height(node-&gt;left_-&gt;right_)) &#123;                // 左孩子的左子树太高                node = rightRotate(node);            &#125; else &#123;                // 左孩子的右子树太高                node = leftBalance(node);            &#125;        &#125;    &#125; else if (node-&gt;data_ &lt; val) &#123;        node-&gt;right_ = insert(node-&gt;right_,val);        if (height(node-&gt;right_) - height(node-&gt;left_) &gt; 1) &#123;            if (height(node-&gt;right_-&gt;right_) &gt;= height(node-&gt;right_-&gt;left_)) &#123;                node = leftRotate(node);            &#125; else &#123;                node = rightBalance(node);            &#125;        &#125;    &#125; else &#123;        // 找到相同节点 不需要向下递归 直接向上回溯    &#125;    // 因为子树添加了新的节点 所以在递归的时候需要更新节点高度    node-&gt;height_ = max(height(node-&gt;left_), height(node-&gt;right_)) + 1;    return node;&#125;// 删除操作 从叶子节点中选出一个节点 进行替换template&lt;typename T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::remove(Node&lt;T&gt; *node, const T &amp;val) &#123;    if (node == nullptr) &#123;        return nullptr;    &#125;    if (node-&gt;data_ &gt; val) &#123;        node-&gt;left_ = remove(node-&gt;left_,val);        if (height(node-&gt;right_) - height(node-&gt;left_) &gt; 1) &#123;            if (height(node-&gt;right_-&gt;right_) &gt;= height(node-&gt;right_-&gt;left_)) &#123;                node = leftRotate(node);            &#125; else &#123;                node = rightBalance(node);            &#125;        &#125;    &#125; else if (node-&gt;data_ &lt; val) &#123;        node-&gt;right_ = remove(node-&gt;right_,val);        if (height(node-&gt;left_) - height(node-&gt;right_) &gt; 1) &#123;            if (height(node-&gt;left_-&gt;left_) &gt;= height(node-&gt;left_-&gt;right_)) &#123;                node = rightRotate(node);            &#125; else &#123;                node = leftBalance(node);            &#125;        &#125;    &#125; else &#123;        // 找到节点        // 如果有两个孩子        if (node-&gt;left_ != nullptr &amp;&amp; node-&gt;right_ != nullptr) &#123;            // 谁高删谁的节点            if (height(node-&gt;left_) &gt;= height(node-&gt;right_)) &#123;                Node&lt;T&gt;* pre = node-&gt;left_;                while (pre-&gt;right_ != nullptr) &#123;                    pre = pre-&gt;right_;                &#125;                node-&gt;data_ = pre-&gt;data_;                node-&gt;left_ = remove(node-&gt;left_,pre-&gt;data_);            &#125; else &#123;                Node&lt;T&gt;* pre = node-&gt;right_;                while (pre-&gt;left_ != nullptr) &#123;                    pre = pre-&gt;left_;                &#125;                node-&gt;data_ = pre-&gt;data_;                node-&gt;right_ = remove(node-&gt;right_,pre-&gt;data_);            &#125;        &#125; else &#123;            // 如果只有一个孩子            if (node-&gt;left_ != nullptr) &#123;                Node&lt;T&gt;* left = node-&gt;left_;                delete node;                return left;            &#125; else if (node-&gt;right_ != nullptr) &#123;                Node&lt;T&gt;* right = node-&gt;right_;                delete node;                return right;            &#125; else &#123;                delete node;                return nullptr;            &#125;        &#125;    &#125;    // 更新节点高度    node-&gt;height_ = max(height(node-&gt;left_), height(node-&gt;right_)) + 1;    return node;&#125;\n\n\n\n性能分析\nAVL树插入一个节点最多只需要两次旋转就可以恢复平衡\n\n插入一个节点会导致节点所在的子树高度加1，但是旋转会让新节点所在子树减1，所以AVL树插入一个节点最多只需要两次旋转就可以了\n\nAVL树删除一个节点最多需要O(logN)次旋转才可以恢复平衡\n\n删除一个节点会导致节点所在子树减1，旋转又会让节点所在的子树减1，所以最坏的时候需要O(logN)次旋转\n\n删除节点 X 之后，R4的平衡因子变为 -2，R4 左旋；R3 的平衡因子变为 2，R3 右旋；R2 的平衡因子变为 -2， R2左旋；R1的平衡因子变为2，R1 右旋\n当从根节点至待删除节点的父节点平衡因子交替为 -1 和 +1，删除该节点一旦触发旋转就需要logn次旋转\n红黑树红黑树的用途非常广泛，像在map\\epoll\\定时器\\Nginx\\CFS\\内存管理中都使用了红黑树对节点进行管理\n红黑树是一颗接近平衡的二叉搜索树，没有AVL树的平衡因子概念，只是靠满足五条性质维持接近平衡的结构，保证最长路径不超过最短路径的2倍\n适用于需要排序的场景下，红黑树不需要像二叉搜索树在极端情况下形成链表导致O(n)的时间复杂度，又不需要像平衡搜索树在维持树的平衡上面过多的性能消耗\n\n性质\n节点是红色或者黑色的\n\n根是黑色的\n\n叶子节点都是黑色（叶子节点是指最底层的空节点，null节点）\n\n红节点的子节点都是黑色的\n\n红节点的父节点是黑色的\n\n从根节点到叶子节点的路径上不会存在两个连续的红节点\n\n\n\n从任意节点到其每个叶子节点的所有路径都包含相同数目的黑节点\n\n\n左旋右旋\n左旋：\n\n将y原来的左子树接到x的右子树下\n\n将y的父节点指向x的父节点，x的父节点原来指向x改为指向y\n\n将x接到y的左子树节点下\n\n\n右旋：\n\n将x原来的右子树接到y的左子树下\n将x的父节点指向y的父节点，y的父节点原来指向y改为指向x\n将y接到x的右子树节点下\n\n\n代码实现\n\n// 左旋void leftRotate(RbTree *T, RbTreeNode *x) &#123;    RbTreeNode *y = x-&gt;right;    // 1.将y原来的左子树接到x的右子树下    x-&gt;right = y-&gt;left;    if (y-&gt;left != T-&gt;nil) &#123;        y-&gt;left-&gt;parent = x;    &#125;    // 2.将y的父节点指向x的父节点,x的父节点原来指向x改为指向y    y-&gt;parent = x-&gt;parent;    if (x-&gt;parent == T-&gt;nil) &#123;        // 此时Y是根节点        T-&gt;root = y;    &#125; else if (x == x-&gt;parent-&gt;left) &#123;        x-&gt;parent-&gt;left = y;    &#125; else &#123;        x-&gt;parent-&gt;right = y;    &#125;    // 3.将x接到y的左子树下    y-&gt;left = x;    x-&gt;parent = y;&#125;// 右旋void rightRotate (RbTree *T, RbTreeNode *y) &#123;    RbTreeNode* x = y-&gt;left;    // 1.将x原来的右子树接到y的左子树下    y-&gt;left = x-&gt;right;    if (x-&gt;right != T-&gt;nil) &#123;        x-&gt;right-&gt;parent = y;    &#125;    // 2.将x的父节点指向y的父节点，y的父节点原来指向y改为指向x    x-&gt;parent = y-&gt;parent;    if (y-&gt;parent == T-&gt;nil) &#123;        T-&gt;root = x;    &#125; else if (y-&gt;parent-&gt;left == y) &#123;        y-&gt;parent-&gt;left = x;    &#125; else &#123;        y-&gt;parent-&gt;right = x;    &#125;    // 3.将y接到x的右子树下    x-&gt;right = y;    y-&gt;parent = x;&#125;\n\n左旋右旋的代码中只不过left和right交换，x和y交换，其他都一样\n增加节点全部都添加到叶子节点中，最后再去调整\n增加的节点默认是红色的，不会去影响路径上黑色节点的数量\n原因：避免每一次加入都需要去旋转\nvoid rbTreeInsert(RbTree *T, RbTreeNode *newNode) &#123;    RbTreeNode* node = T-&gt;root;    RbTreeNode* parent = T-&gt;nil;    // 寻找可以插入的位置 找到叶子节点    while (node != T-&gt;nil) &#123;        parent = node;        if (newNode-&gt;key &lt; node-&gt;key) &#123;            node = node-&gt;left        &#125; else if (newNode-&gt;key &gt; node-&gt;key) &#123;            node = node-&gt;right;        &#125; else &#123;            return; // 具体相同的值要不要改动看需求        &#125;    &#125;    newNode-&gt;parent = parent;    if (parent == T-&gt;nil) &#123;        T-&gt;root = newNode;    &#125; else if (parent-&gt;key &gt; newNode-&gt;key) &#123;        parent-&gt;left = newNode;    &#125; else &#123;        parent-&gt;right = newNode;    &#125;    newNode-&gt;left = T-&gt;nil;    newNode-&gt;right = T-&gt;nil;    newNode-&gt;color = RED;    rbTreeInsertFixup(T,newNode);&#125;\n\n树的调整当父节点为红色节点的时候就需要调整，因为违反了规则四\n调整的过程中会遇到三种情况：\n\n叔父节点是红色\n叔父节点是黑色，当前节点父节点是左子树\n叔父节点是黑色，当前节点父节点是右子树\n\n如果叔父节点是红色那么在左右不需要区分，没有什么区别，到时候祖父节点改为红色，父节点和叔父节点改为黑色继续向上调整\n但是如果是黑色就需要区分了，因为父节点和祖父节点颜色的时候会导致黑色路径高度发生变化\n目前已知的情况：\n\n当前节点是红色\n父节点是红色\n祖父节点是黑色\n\n\n叔父节点是红色的\n\n\n将父亲和叔父都改为黑色，此时黑色路径长度发生变化，需要将祖父改为红色\n从祖父开始继续向上调整\n\n父亲是祖父的左孩子\n\n自己是父亲的左孩子：\n\n将父亲变为黑色，此时左边黑色路径发生变化，需要将祖父改为红色\n此时右子树黑色路径减少，需要对祖父右旋，将父节点成为新祖父恢复右子树的黑色高度\n自己是父亲的右孩子：\n\n将父亲左旋变为父亲是自己的左孩子，就变成上面的情况了\n\n父亲是祖父的右孩子\n\n自己是父亲的右孩子：\n\n将父亲变为黑色，此时右边黑色路径变长，将祖父变为红色\n此时左边黑色路径变短，进行左旋恢复左子树高度\n自己是父亲的左孩子：\n\n对父亲进行右旋让父亲成为自己的右孩子变成上面的情况\n// 调整树void rbTreeInsertFixup(RbTree *T, RbTreeNode *node) &#123;    // 如果父节点是黑色的则不需要调整    while (node-&gt;parent-&gt;color == RED) &#123;        // 父节点是祖父节点的左子树        if (node-&gt;parent == node-&gt;parent-&gt;parent-&gt;left) &#123;            // 叔父节点            RbTreeNode *uncle = node-&gt;parent-&gt;parent-&gt;right;            if (uncle-&gt;color == RED) &#123;                // 将父节点改为黑色和叔父节点改为黑色，祖父节点改为红色继续向上调整就可以了                // 会影响到黑色路径的长度                node-&gt;parent-&gt;color = BLACK;                uncle-&gt;color = BLACK;                node-&gt;parent-&gt;parent-&gt;color = RED;                // 继续向上调整                node = node-&gt;parent-&gt;parent;            &#125; else &#123;                if (node == node-&gt;parent-&gt;right) &#123;                    // 左旋                    node = node-&gt;parent;                    leftRotate(T,node);                &#125;                // 让父节点变为黑色，祖父节点变为红色（右子树的黑色高度变低了）                // 对祖父右旋，让父节点成为新祖父，恢复右子树的高度                // 这种情况只需要两次旋转就可以完成调整了                node-&gt;parent-&gt;color = BLACK;                node-&gt;parent-&gt;parent-&gt;color = RED;                rightRotate(T,node-&gt;parent-&gt;parent);            &#125;        &#125; else &#123;            RbTreeNode *uncle = node-&gt;parent-&gt;parent-&gt;left;            if (uncle-&gt;color == RED) &#123;                node-&gt;parent-&gt;color = BLACK;                uncle-&gt;color = BLACK;                node-&gt;parent-&gt;parent-&gt;color = RED;                node = node-&gt;parent-&gt;parent;            &#125; else &#123;                if (node == node-&gt;parent-&gt;left) &#123;                    node = node-&gt;parent;                    rightRotate(T,node);                &#125;                // 左子树的高度减小了                node-&gt;parent-&gt;color = BLACK;                node-&gt;parent-&gt;parent-&gt;color = RED;                leftRotate(T,node-&gt;parent-&gt;parent);            &#125;        &#125;    &#125;    T-&gt;root-&gt;color = BLACK;&#125;\n\n删除节点定义三种节点：\n\n覆盖节点Z：被指定删除的结点，实际上是通过被覆盖实现\n删除节点Y：实际上被删除的节点，一般是后继节点\n轴心节点X：维护红黑树的节点\n\n删除的节点可能有三种情况：\n\n没有左右子树：直接删除\n有且只有一颗子树：将该节点的唯一子树挂到父节点上，然后删除该节点\n左右子树都有：找一个后继节点Y覆盖指定节点Z，然后删除节点Y，Y是情况1或2中的一种\n\n如果当前结点是父结点的左子树的情况，可以归纳出来四种情况。同理如果当前结点是父结点的右子树，我们也可以归纳出来四种情况。但是这四种情况的差异就是旋转方向的区别而已（镜像的）。一共是8种情况，但是归纳出来其实是4种\n当前节点是父节点的左子树情况一：当前节点的兄弟节点是红色将兄弟变为黑色，父亲变为红色，此时左边高度降低，对父节点左旋恢复左子树高度，此时兄弟的左孩子变为新的兄弟，变为情况2、3、4\n（因为要让x的兄弟是黑色，所以只能从左右侄子中获得）\n\n情况二：兄弟为黑色，左右侄子也是黑色此时兄弟和自己都是黑色，父节点为红色或黑色\n将兄弟变为红色，轴心节点变为父节点（原来的轴心节点所在路径少了一个黑色节点，所以将兄弟变为红色，此时父节点的黑色路径是相同的了，但是父节点之上的路径少了一个黑色节点，所以将轴心节点变为父节点，继续调整）\n\n情况三：兄弟是黑色，右侄子是黑色，左侄子是红色将左侄子变为黑色，兄弟变为红色，此时右子树黑色高度降低，对兄弟节点继续右旋恢复高度，此时左侄子成为新的右兄弟\n此时兄弟的右儿子是红色，符合情况4，按照情况4的方法继续调整\n\n情况四：兄弟是黑色，右侄子是红色，左侄子是红色或黑色将兄弟颜色改为和父节一样，右侄子和父节点都变为黑色\n为了保证父节点变为黑色后高度不变需要将父节点左旋\nx指向根节点，循环结束\n为什么要将右侄子变为黑色：因为经过左旋后右侄子变为新的兄弟，代替了原来的兄弟，所以需要变为和兄弟颜色一样，也就是黑色\n为什么要将兄弟变为和父节点一样：因为经过左旋后兄弟代替了父节点\n为什么要将父节点变为黑色：因为父节点左旋弥补了被删除的黑色节点\n此时路径恢复了\n\n当前节点是父节点的右子树和上面的情况一样，是镜像的\n总结会有两种情况导致循环退出不再需要调整：\n情况二的时候轴心节点变为父节点，如果父节点是红色那么就可以退出将父节点改为黑色就可以恢复高度了\n情况四：通过使用父节点弥补被删除节点恢复高度，最后再将轴心节点置为根节点退出循环\n每一种情况都是尽可能向第四种情况靠近，实现兄弟是黑色，右侄子是红色的情况\n代码// 寻找x节点的最左节点RbTreeNode* rbTree_mini(RbTree *T, RbTreeNode *x) &#123;    while (x-&gt;left != T-&gt;nil) &#123;        x = x-&gt;left;    &#125;    return x;&#125;// 寻找覆盖节点的右子树的最左节点RbTreeNode* rbTree_successor(RbTree *T, RbTreeNode* x) &#123;    RbTreeNode *y = x-&gt;parent;    // 寻找x节点的右子树的最左节点    if (x-&gt;right != T-&gt;nil) &#123;        return rbTree_mini(T,x-&gt;right);    &#125;&#125;void rbTree_delete_fixup(RbTree *T, RbTreeNode* x) &#123;    while ((x != T-&gt;root) &amp;&amp; (x-&gt;color == BLACK)) &#123;        if (x == x-&gt;parent-&gt;left) &#123;            // w为兄弟节点            RbTreeNode *w = x-&gt;parent-&gt;right;            if (w-&gt;color == RED) &#123;                w-&gt;color = BLACK;                x-&gt;parent-&gt;color = RED;                leftRotate(T,x-&gt;parent);                w = x-&gt;parent-&gt;right;            &#125;            if ((w-&gt;left-&gt;color == BLACK) &amp;&amp; (w-&gt;right-&gt;color == BLACK)) &#123;                w-&gt;color = RED;                x = x-&gt;parent;            &#125; else &#123;                if (w-&gt;right-&gt;color == BLACK) &#123;                    w-&gt;left-&gt;color = BLACK;                    w-&gt;color = RED;                    rightRotate(T,w);                    w = x-&gt;parent-&gt;right;                &#125;                w-&gt;color = x-&gt;parent-&gt;color;                x-&gt;parent-&gt;color = BLACK;                w-&gt;right-&gt;color = BLACK;                leftRotate(T,x-&gt;parent);                x = T-&gt;root;            &#125;        &#125; else &#123;            RbTreeNode *w = x-&gt;parent-&gt;left;            if (w-&gt;color == RED) &#123;                w-&gt;color = BLACK;                x-&gt;parent-&gt;color = RED;                rightRotate(T,x-&gt;parent);                w = x-&gt;parent-&gt;left;            &#125;            if ((w-&gt;left-&gt;color == BLACK) &amp;&amp; (w-&gt;right-&gt;color == BLACK)) &#123;                w-&gt;color = RED;                x = x-&gt;parent;            &#125; else &#123;                if (w-&gt;left-&gt;color == BLACK) &#123;                    w-&gt;right-&gt;color = BLACK;                    w-&gt;color = RED;                    leftRotate(T,w);                    w = x-&gt;parent-&gt;left;                &#125;                w-&gt;color = x-&gt;parent-&gt;color;                x-&gt;parent-&gt;color = BLACK;                w-&gt;left-&gt;color = BLACK;                rightRotate(T,x-&gt;parent);                x = T-&gt;root;            &#125;        &#125;    &#125;    x-&gt;color = BLACK;&#125;// 删除节点RbTreeNode* rbTreeDelete(RbTree *T, RbTreeNode *z) &#123;    // z是被覆盖的节点 y是删除节点 x是轴心节点负责旋转    RbTreeNode *y = T-&gt;nil;    RbTreeNode *x = T-&gt;nil;    // 此时如果没有子树或只有一颗子树 那么就是要被删除的节点    if ((z-&gt;left == T-&gt;nil) || (z-&gt;right == T-&gt;nil)) &#123;        y = z;    &#125; else &#123;        // 寻找删除节点 也就是覆盖节点的右子树的最左节点        y = rbTree_successor(T,z);    &#125;    // 找轴心节点 一般是被删除节点的左子节点    if (y-&gt;left != T-&gt;nil) &#123;        x = y-&gt;left;    &#125; else if (y-&gt;right != T-&gt;nil) &#123;        x = y-&gt;right;    &#125;    x-&gt;parent = y-&gt;parent;    if (y-&gt;parent == T-&gt;nil) &#123;        // 如果y是根节点 那么x就成为新的根节点        T-&gt;root = x;    &#125; else if (y == y-&gt;parent-&gt;left) &#123;        y-&gt;parent-&gt;left = x;    &#125; else &#123;        y-&gt;parent-&gt;right = x;    &#125;    // 覆盖节点    if (y != z) &#123;        z-&gt;key = y-&gt;key;        z-&gt;value = y-&gt;value;    &#125;    // 如果删除节点是黑色节点则需要调整    if (y-&gt;color == BLACK) &#123;        rbTree_delete_fixup(T,x);    &#125;    return y;&#125;\n\n时间复杂度\n就插入节点导致树失衡的情况，AVL和RB-Tree都是最多两次树旋转来实现复衡，旋转的量级是O(1)\n删除节点导致失衡，AVL需要维护从被删除节点到根节点root这条路径上所有节点的平衡，旋转的量级为O(logN)，而RB-Tree最多只需要旋转3次实现复衡，只需O(1)，所以说RB-Tree删除节点的rebalance的效率更高，开销更小！\n但是红黑树是通过改变节点颜色来避免旋转，具体开销还是要看改变颜色开销小还是改变指针开销小\nB树与B+树B树\n性质一颗M阶B树T满足一下条件：\n\n每个结点最多拥有M棵子树\n根结点至少拥有两棵子树\n除了根节点以外，其余每个分支节点至少拥有M&#x2F;2棵子树（保证树的平衡）\n所有的叶子节点都在同一层\n有k棵子树的分支节点则存在k-1个关键字，关键字按照递增顺序进行排序\n关键字数量满足ceil(M&#x2F;2)-1 &lt;&#x3D; n &lt;&#x3D; M-1\n\n查找首先从根节点开始查找，比较根节点中的关键字，如果比关键字大就在关键字的右边子节点查找，否则向左边子节点查找\n比如查找P，判断出M比P小所以向右边的子树查出，读取QT的那一颗树，判断出比Q小，所以在QT树的最左边子树查找得到NP，在NP中查找到P关键字\n插入比如上图中的树是一颗5阶树，首先查找可以存放的位置，如果可以存放就直接存放，否则需要进行叶子节点的分裂\n首先插入3、8、31、11：此时节点已经有四个关键字了，所以后面要继续插入的时候需要进行页的分裂，页的分裂就是将中间节点作为左右节点的父节点\n\n插入23、29：\n\n插入50、28、53：\n\n删除当关键字小于m&#x2F;2时就需要进行节点的合并：\n\n相邻两颗子树都是M&#x2F;2-1则合并\n左边子树大于m&#x2F;2-1则向左边子树借\n右边子树大于m&#x2F;2-1则向右边子树借\n\n删除A节点：\n由于CF只有两个节点所以需要借节点，向右边的子树借一个节点，也就是将L变为根节点，I节点给CF子树\n\n\nAB、DE子树只有两个节点，所以进行合并：\n\n将A节点删除：\n总结B树相比于平衡二叉树在节点空间利用率上做了改进，一个节点能够容纳更多的数据，从而减少树的高度，减少查询的速度，很适合于磁盘上数据的存储\n多叉树和B树之间的区别：\n\n多叉树没有约束平衡\n多叉树没有约束每个节点子树的数量\nB树数据是按顺序排列的\n\nB+树查询和B树大体相似，但是B+树所有的数据存放在叶子节点中，所以需要从根节点开始向下查找直到到达叶子节点\n插入插入全部在叶子节点上进行，按照关键字大小顺序排列\n当叶子节点中关键字数量超过限制时需要进行节点的分裂\n阶数限制为3：\n插入95：插入关键字所在结点 [85、91、97] 包含 3 个关键字，等于阶数 M ，则将 [85、91、97] 分裂为两个结点 [85、91] 和结点 [97] , 关键字 95 插入到结点 [95、97] 中，并将关键字 91 上移至其双亲结点中，发现其双亲结点 [72、97] 中包含的关键字的个数 2 小于阶数 M ，插入操作完成\n\n删除\n在叶子节点删给删除，如果不会破坏规则则直接删除\n\n如果删除的是父节点中的最大或最小关键字会涉及到更改双亲结点一直到根节点中所有关键字的修改：\n\n\n删除整颗 B+树中最大的关键字 97 为例，查找并删除关键字 97 ， 然后向上回溯，将所有关键字 97 替换为次最大的关键字 91\n\n\n删除节点后如果导致节点关键字数量小于[M&#x2F;2]：\n如果兄弟节点可以借则向兄弟节点借\n如果没有则和兄弟节点合并\n\n\n\n删除51：向[21,37,44]的兄弟节点借，同时修改双亲结点中的关键字\n\n删除59：发现该结点的兄弟结点 [21、37] 包含的关键字的个数 2 等于 ⌈M/2⌉， 所以删除关键字 59 ，并将结点 [21、37] 和 [44] 进行合并 [21、37、44] ，然后向上回溯，将所有关键字 59 替换为次最大的关键字 44\n\n总结B+树是B树的基础上进行了改进，区别是：\n\nB+树的高度比B树低，磁盘IO次数更少：B树的内部节点和叶子节点都保存了键值，导致每一个节点能够存放的记录数比较少，要保存相同的记录数就需要更多的节点，进而导致树高度的增加。B+树的非叶子节点只存放索引不存放数据，能够容纳更多的记录，因此B+树高度比B树低\n\n\nB+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳\nB+树范围查询效率高：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便。但是B树需要通过中序遍历在父子节点之间来回跳转\nB+树的插入和删除效率更高：B+树有大量冗余的节点，使得B+树在删除和插入时效率比较高，很少涉及树的变形\n\nB*树在B+树的构建过程中，为了保持树的平衡，节点的合并拆分是比较耗费时间的，所以B树就是在*如何减少构建中节点合并和拆分的次数，从而提升树的数据插入、删除性能\n区别：\n\n关键字个数上：B+树初始化的关键字初始化个数是cei(m&#x2F;2)，b*树的初始化个数为（cei(2&#x2F;3 *m)）\nB+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1&#x2F;3的数据创建一个新的节点出来\nB*树在内部节点和叶子节点都增加了指向兄弟节点的指针\n\nTrie字典树性质\n根节点不包含字符，除根节点外每个节点都只包含一个字符\n从根节点到任意节点，路径上经过的字符连接起来，为该节点对应的字符串\n每个节点的所有子节点包含的字符都不相同\n\n性能分析搜索时间复杂度O(m)，m为字符串的长度\n补充应用场景：串的快速检索、串排序、前缀搜索\n核心：利用字符串的公共前缀减少查询时间\n跳表在原来有序链表的基础上增加了多级索引，通过索引快速查找\n性质\n由许多层链表组成\n每一层都是有序的链表\n最底层Level 1的链表包含所有元素\n如果一个元素出现在Level i的链表中，则在Level i之下的链表都会出现\n每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下一层的元素\n\n\n操作搜索：从最上层元素开始搜索，找到就直接返回；找不到就根据该层元素向下一层查找\n删除：在各个层中找到包含目标数的节点将其删除\n插入\n\n插入元素的时候元素所占有的层数是随机的，由随机算法产生\n\n类似抛硬币，K满足p&#x3D;1&#x2F;2的正太分布，实现上一层元素的数量是下一层的一半，实现二分查找，类似比如得到K&#x3D;2，那么1,2层都会插入该元素\n\n\n先确定元素要占据的层数K，在Level1~K的各个层都插入数据\n\n\n性能分析O(logN)\n和红黑树对比\n实现简单\n跳跃表的增加、删除操作只会改动局部，不像红黑树的增加、删除操作，因为需要节点重新着色和旋 转，可能整棵树都要进行调整，因此在并发环境下，跳跃表加锁的粒度会更小一些，并发能力更强\n因为跳跃表的每一层都是一个有序的链表，因此范围查找非常方便，优于红黑树的范围搜索的\n\n跳跃表相比于红黑树，是用空间换时间（level 2层开始每一层都有会存储重复的数据），因此占用的内存空间比红黑树大\n倒排索引全文检索：在大量文档中找到包含某个单词出现的位置\n\nlike %单词%\n\n无法使用数据库的索引\n\n搜索效果差，无法实现复杂的搜索需求\n\n\n\n\n正排索引：以文档对象的唯一ID为索引，以文档内容为记录\n倒排索引：将文档内容中的单词作为索引，将包含该词的文档ID作为记录\n过程\n\n通过正排索引为每个文档赋予唯一的ID标识\n\n\n\n\n生成倒排索引\n\n对文档内容分为多个单词\n\n按照单词作为索引，对应的文档id作为记录（链表）\n\n\n\n\n\n\n查找\n\n将查找内容分词通过倒排索引找到文档id，再对文档id取交集\n\n\n\n\n\n\n哈夫曼树 &amp; 哈夫曼编码哈夫曼树又称为最佳判定树、最优二叉树，是一种带权路径长度最短的二叉树，常用于数据压缩。 所谓树的带权路径长度，就是树中所有的叶子节点的权值乘以 其到根节点的路径长度\n哈夫曼编码目的：为给定的字符集合构建二进制编码，使得编码的期望长度达到最短\n哈夫曼编码不同于ASCII和Unicode这些字符编码，这些字符集中的码长都采用的是长度相同的编码方 案，而哈夫曼编码使用的是变长编码，而且哈夫曼编码满足立刻可解码性（就是说任一字符的编码都不 会是另一个更长字符编码的前缀），这样当一个字符的编码中的位被接收时，可以立即进行解码而无须 等待之后的位来决定是否存在另一个合法的更长的编码\n","categories":["数据结构"],"tags":["数据结构"]}]